{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # UIB 11762 CBIR Assignment 2: Image Indexing\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Before you begin, please put your name and DNI here:**\n",
    "\n",
    " > Marc BALLE SANCHEZ, 43213875A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apuntes importantes \n",
    "\n",
    "1. Para la ejecución de esta práctica he tenido que migrar a un *entorno local* ya que la plataforma Google Colab presentaba irregularidades respecto a los tiempos de ejecución de mismo bloques de código. Así pues, todos aquellos datos necesarios para la ejecución de la práctica han sido descargados previamente y se han eliminado aquellas celdas encargadas de ello. \n",
    "\n",
    "2. Esta práctica es una segunda versión de la que ya se entregó. En esta ocasión soluciono un problema que se tenía con el TF-IDF. Los detalles se comentan en la sección pertinente.  \n",
    "\n",
    "3. A parte de imprimir datos de interés para la construcción de conclusiones y respuestas, también se han impreso al final de cada apartado los valores de una serie de listas que, en un principio, se concibieron para generar una serie de plots. En la sección del BoW esta impresión es excesivamente grande. Esta información es irrelevante y no debe ser tenida en cuenta.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code for this assignment\n",
    "import cv2\n",
    "import scipy.cluster.vq as vq\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Please, justify all of your answers, graphically wherever possible.\n",
    " >\n",
    " > Remember that this notebook will be considered as a report to the work done during the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Introduction\n",
    " ---\n",
    " In this assignment, you will implement and evaluate different methods for indexing images. As usual during this course, we will use the [INRIA Holidays](http://lear.inrialpes.fr/people/jegou/data.php) dataset. **Check the Assignment 1 to further information about the dataset.**\n",
    "\n",
    " Let's download it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A folder named *holidays* is now available in your workspace, containing:\n",
    " * A set of 1491 images, and\n",
    " * A file called *holidays_images.dat*, which is a list with the names of the 1491 images. This file can be used to generate a ground truth.\n",
    "\n",
    " > **NOTE**: If you prefer, you can upload the dataset(s) to your Google Drive and mount it in the notebook as explained [here](https://www.youtube.com/watch?v=IZUz4pRYlus).\n",
    "\n",
    " We also need the script to evaluate a CBIR system on this dataset. Remember that the performance is measured computing the **mean average precision** (mAP) over all queries. Let's download this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_holidays as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check the Assignment 1 to remember how to use this script and the different functionalities it offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we did in the previous assignment, next step is to create four lists:\n",
    " - **query_names**: File names of the *query* images.\n",
    " - **query_imgs**: *Query* images loaded using OpenCV2.\n",
    " - **train_names**: File names of the *train* (database) images.\n",
    " - **train_imgs**: *Train* images loaded using OpenCV2.\n",
    "\n",
    " The size of the images is reduced in order to speed up the process during the rest of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "991\n"
     ]
    }
   ],
   "source": [
    "# Separating the dataset into query and train images\n",
    "query_names = []\n",
    "query_imgs = []\n",
    "train_names = []\n",
    "train_imgs = []\n",
    "\n",
    "with open('holidays/holidays_images.dat') as f:\n",
    "    for line in f:\n",
    "        imname = line.strip()\n",
    "        imno = int(imname[:-len(\".jpg\")])\n",
    "        img = cv2.imread('holidays/' + imname)\n",
    "        img = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Checking if this is a query image\n",
    "        if imno % 100 == 0:\n",
    "            query_names.append(imname)\n",
    "            query_imgs.append(img)\n",
    "        else:\n",
    "            train_names.append(imname)\n",
    "            train_imgs.append(img)\n",
    "\n",
    "print(len(query_imgs))\n",
    "print(len(train_imgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this assignment we will create four additional lists:\n",
    "\n",
    " - **query_kps**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *query* images.\n",
    " - **query_desc**: A list of Numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *query* images.\n",
    " - **train_kps**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *train* (database) images.\n",
    " - **train_desc**: A list of Numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *train* images.\n",
    "\n",
    " Unlike in Assigment 1, here you will be provided with a set of SIFT descriptors for each image, and, therefore, you do not need to create these lists from scratch. First, let's download the descriptors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, a new directory called *siftgeo* is in your workspace, containing the set of SIFT descriptors for each image of the dataset. These descriptors are stored in binary format and, thus, you will need some tools to load them. You are also provided with tools for that purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import index_utils as iu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One loaded, you can call the function `load_SIFT_descriptors` to load the descriptors of a list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "991\n",
      "500\n",
      "991\n",
      "(1000, 128)\n",
      "[[10.  6. 52. ... 15.  4.  0.]\n",
      " [16. 50. 12. ... 15.  4.  0.]\n",
      " [10. 11. 58. ...  7.  4.  4.]\n",
      " ...\n",
      " [27. 15.  0. ... 16.  8. 12.]\n",
      " [51. 47. 14. ... 35. 26.  0.]\n",
      " [ 2. 37. 25. ... 47. 13.  8.]]\n"
     ]
    }
   ],
   "source": [
    "query_kps, query_desc = iu.load_SIFT_descriptors(query_names, max_desc=1000)\n",
    "train_kps, train_desc = iu.load_SIFT_descriptors(train_names, max_desc=1000)\n",
    "\n",
    "# Some prints\n",
    "print(len(query_kps))\n",
    "print(len(train_kps))\n",
    "print(len(query_desc))\n",
    "print(len(train_desc))\n",
    "print(query_desc[0].shape)\n",
    "print(query_desc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For development purposes, we use the parameter `max_desc` to load a maximum number (1000) of the descriptors. This will speed up the execution of the rest of the notebook, while the decrease in performance will be minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## $k$-d Trees\n",
    " ---\n",
    " In this section you will use a set of randomized $k$-d trees to index the database of images. Given a query image, the best matching image will be the one with the higher number of matches, according to the Nearest Neighbor Distance Ratio (NNDR). Write a function called `build_db_kdtrees` to build a set of randomized $k$-d trees given a set of training descriptors:\n",
    "\n",
    " > **Useful links**: [cv2.FlannBasedMatcher](https://docs.opencv.org/3.4/dc/de2/classcv_1_1FlannBasedMatcher.html), [Possible algorithms to create an index](https://docs.opencv.org/4.5.1/db/d18/classcv_1_1flann_1_1GenericIndex.html#a8fff14185f9f3d2f2311b528f65b146c), [Algorithms IDs](https://github.com/opencv/opencv/blob/master/modules/flann/include/opencv2/flann/defines.h#L70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_db_kdtrees(img_names, descs, ntrees = 4):\n",
    "    '''\n",
    "    Builds a set of randomized k-d trees.\n",
    "    \n",
    "    - img_names: An ordered list with the image names.\n",
    "    - descs: A list of length len(img_names) where each element is a numpy array \n",
    "            of size (ndesc_for_this_image, 128). Each Numpy array i corresponds \n",
    "            to the descriptors found on image i.\n",
    "    - ntrees: Number of trees to train.\n",
    "\n",
    "    RETURNS: \n",
    "    - index: trained FLANN index.\n",
    "    - id_to_img: An associative list to link every image id to the its real name\n",
    "            e.g. id_to_img[0] = '100001.jpg', id_to_img[1] = '100002.jpg'.\n",
    "    '''\n",
    "\n",
    "    index = []\n",
    "    id_to_img = []\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO:                                                                      #\n",
    "    # Write this function according to the description given above.              #\n",
    "    ##############################################################################\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = ntrees)\n",
    "    search_params = {}  #{} \n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    start = time.time()\n",
    "    flann.add(descs)\n",
    "    flann.train()\n",
    "    stop = time.time()\n",
    "\n",
    "    training_time = stop - start\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                                 END OF YOUR CODE                           #\n",
    "    ##############################################################################\n",
    "\n",
    "    #return index#,id_to_img\n",
    "    return flann, training_time #id_to_img -> es el mismo que train_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, write a function to search an image in a generic index (database). You should search the descriptors of the query image and obtain their two closest SIFT descriptors in the database. Next, the initial set of matches should be filtered using the NNDR criterion, as in the previous assignment. For each database image, its final score with regard to this query image will be the number of correct matches with this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_image(descs, index, train_names):\n",
    "    '''\n",
    "    Search an image in the index\n",
    "    \n",
    "    - descs: A numpy array. This is the set descriptors \n",
    "            extracted from the query image.\n",
    "    - index: FLANN index to search for descriptors.\n",
    "    - id_to_name: An associative list to link every image index to its real name\n",
    "            e.g. id_to_img[0] = '100001.jpg', id_to_img[1] = '100002.jpg'\n",
    "\n",
    "    RETURNS: \n",
    "    - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "    '''\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO:                                                                      #\n",
    "    # Write this function according to the description given above.              #\n",
    "    ##############################################################################\n",
    "    \n",
    "    ratio = 0.75\n",
    "    init_dict = [(img_name, 0) for img_name in train_names]\n",
    "    score = dict(init_dict)\n",
    "    start = time.time()\n",
    "    matches = index.knnMatch(descs, k = 2) \n",
    "    stop = time.time()\n",
    "    filt_matches = list(filter(lambda m: m[0].distance < m[1].distance * ratio, matches))\n",
    "    for match in filt_matches: \n",
    "        score[train_names[match[0].imgIdx]]+=1\n",
    "\n",
    "    #score_cp = copy.deepcopy(score) #elimino imágenes con 0 matches\n",
    "    #for entry in score_cp.keys(): \n",
    "    #    if not score_cp[entry]:\n",
    "    #        score.pop(entry) \n",
    "\n",
    "    values = np.array(list(score.values()))\n",
    "    imgs_names = list(score.keys())\n",
    "    index_sort = np.argsort(values)[::-1] #descending order \n",
    "    best_imgs = [imgs_names[i] for i in index_sort]\n",
    "    \n",
    "    query_time = stop-start\n",
    "    return best_imgs, query_time\n",
    "\n",
    "    ##############################################################################\n",
    "    #                                 END OF YOUR CODE                           #\n",
    "    ##############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, write a function called `compute_mAP`. Given a list of query images and a trained index, this function should return a Python dictionary with the ordered results for each query along with the computed mAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(query_names, query_descs, index, train_names, gt_file = 'holidays/holidays_images.dat'):\n",
    "    '''\n",
    "    Perform a search for a list of query images against the database.\n",
    "    \n",
    "    - query_names: An ordered list with the names of the query images.\n",
    "    - query_desc: A list containing numpy arrays of size \n",
    "            (ndesc_for_this_image, 128). Each numpy array i corresponds to the \n",
    "            descriptors found at image i.\n",
    "    - index: FLANN index.\n",
    "    - id_to_name: An associative array to link every image index to its real name\n",
    "            e.g. id_to_img[0] = '100001.jpg', id_to_img[1] = '100002.jpg'\n",
    "    - gt_file = Ground truth file. Typically, 'holidays_images.dat'.\n",
    "\n",
    "    RETURNS: \n",
    "    - total_results: A dictionary containing, for each query image, \n",
    "            an ordered list of the retrieved images.\n",
    "    - m_ap: Mean Average Precision averaged over all queries.\n",
    "    '''\n",
    "    total_results = {}\n",
    "    m_ap = 0.0\n",
    "    query_times = []\n",
    "    ##############################################################################\n",
    "    # TODO:                                                                      #\n",
    "    # Write this function according to the description given above.              #\n",
    "    ##############################################################################\n",
    "    \n",
    "    for query_name, query_desc in zip(query_names, query_descs):\n",
    "            results, query_time = search_image(query_desc, index, train_names)\n",
    "            total_results[query_name] = results \n",
    "            query_times.append(query_time)\n",
    "        \n",
    "    m_ap = ev.compute_mAP(total_results, gt_file)\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                                 END OF YOUR CODE                           #\n",
    "    ##############################################################################\n",
    "    \n",
    "    return total_results, m_ap, np.array(query_times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Questions**: Search the query images against the database using the `compute_mAP` function.\n",
    " >\n",
    " > - What is the mAP obtained using this approach?\n",
    " \n",
    " >   <font color = 'blue'>El mAP obtenido se calcula en base a las imágenes devueltas por la base de datos ordenadas en un orden tal que las primeras sean las más parecidas a la imagen de petición y las últimas las más diferentes. En el caso de los kd-trees, la búsqueda lineal se sustituye por una búsqueda en un árbol binario. En dicho árbol cada nodo hoja es un descriptor de alguna imágen de la base de datos. A cada descriptor de la imagen de petición se le asignan en este caso los dos descriptores más cercanos buscados a lo largo de varios kd-trees. Una vez filtrados dichos emparejamientos según el criterio NNDR, se obtienen las correspondencias entre los descriptores e imágenes de entrenamiento y se actualiza un contador en función de la imagen a la que pertenecen cada descriptor emparejado. Así, las imágenes con más votos son devueltas en las primeras posiciones.</font>\n",
    " \n",
    " > - Is it stable? Why?\n",
    " \n",
    " >    <font color = 'blue'>Para comprobar si el mAP devuelto es estable, se ha repetido el proceso de búsqueda 3 veces. Como puede contemplarse en los datos impresos por pantalla, el mAP varía muy poco entre iteraciones. De esta manera, puede concluirse que sí es estable.</font> \n",
    " \n",
    " > - Analyze the effect of changing the **number of trees** in terms of mAP and average response time. Some plots here can be useful to justify your answer.\n",
    " \n",
    " >   <font color = 'blue'>Para contestar a esta cuestión se ha probado a costruir un indice con 3, 4 y 5 árboles. Como puede observase en las impresiones, tanto el mAP como el tiempo total de contrucción y búsqueda de cada índice son muy parecidos. Sí que es cierto que a cuanto más árboles más tarda el proceso completo de contrucción y búsqueda. Al final esto parece lógico ya que tanto la construcción del índice y la indexación de descriptores tarda más a cuántos más árboles tenga uno que referirse o prestar atención (por decirlo de alguna manera). Sin embargo, no parece ser que a cuántos más árboles mejor es el mAP. El mejor valor de dicha métrica se obtiene para 4 árboles, aunque la diferencia con el resto de índices es muy baja, menor al 0,01. Por ello, no puede decirse que sea una diferencia significativa.</font> \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "\n",
      "MAP: 0.6879927943384108 \n",
      "\n",
      "Training time: 4.547006845474243 secs.\n",
      "Query response time: 0.06576506376266479 +- 0.01895761496540475 secs.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "MAP: 0.6975660353881761 \n",
      "\n",
      "Training time: 4.711634159088135 secs.\n",
      "Query response time: 0.07384067058563232 +- 0.03547091900240361 secs.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "MAP: 0.6839776488979906 \n",
      "\n",
      "Training time: 4.5130650997161865 secs.\n",
      "Query response time: 0.06369509649276733 +- 0.01834816880132994 secs.\n",
      "\n",
      "\n",
      "\n",
      "Mean training time Kd-trees: 4.5905687014261884 secs.\n",
      "Mean query response time Kd-trees: 0.06776694361368814 secs\n",
      "Number of trees: 3\n",
      "MAP: 0.6900373167008104\n",
      "\n",
      "Average response time: 36.9909930229187 secs.\n",
      "\n",
      "\n",
      "\n",
      "Number of trees: 4\n",
      "MAP: 0.6995479688941076\n",
      "\n",
      "Average response time: 39.15631985664368 secs.\n",
      "\n",
      "\n",
      "\n",
      "Number of trees: 5\n",
      "MAP: 0.6922023578233276\n",
      "\n",
      "Average response time: 42.34748888015747 secs.\n",
      "\n",
      "\n",
      "\n",
      "Printing variables: \n",
      "\n",
      "m_ap_list: [0.6900373167008104, 0.6995479688941076, 0.6922023578233276] \n",
      "\n",
      "time_tree: [36.9909930229187, 39.15631985664368, 42.34748888015747] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write here the code required to answer the questions stated above. You can   #\n",
    "# Add more cells at this point if you need it.                                 #\n",
    "################################################################################\n",
    "\n",
    "mean_train_t_kd = 0.0\n",
    "mean_query_t_kd = 0.0\n",
    "niters = 3\n",
    "for i in range(niters):\n",
    "    index, train_time_kd = build_db_kdtrees(train_names, train_desc, ntrees = 3)\n",
    "    results, m_ap, query_time_kd = compute_mAP(query_names, query_desc, index, train_names)\n",
    "    mean_train_t_kd += train_time_kd\n",
    "    mean_query_t_kd += np.mean(query_time_kd)\n",
    "    print('Iteration {}\\n'.format(i))\n",
    "    print('MAP: {} \\n'.format(m_ap))\n",
    "    print('Training time: {} secs.'.format(train_time_kd))\n",
    "    print('Query response time: {} +- {} secs.'.format(np.mean(query_time_kd), np.std(query_time_kd)))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "\n",
    "print ('Mean training time Kd-trees: {} secs.'.format(mean_train_t_kd/niters))\n",
    "print('Mean query response time Kd-trees: {} secs'.format(mean_query_t_kd/niters))\n",
    "\n",
    "num_trees = [3,4,5]\n",
    "m_ap_list = []\n",
    "time_tree = []\n",
    "for tree in num_trees: \n",
    "    start = time.time()\n",
    "    index, _ = build_db_kdtrees(train_names, train_desc, ntrees = tree)\n",
    "    results, m_ap, _ = compute_mAP(query_names, query_desc, index, train_names)\n",
    "    stop = time.time()\n",
    "    m_ap_list.append(m_ap)\n",
    "    time_tree.append(stop-start)\n",
    "    print('Number of trees: {}'.format(tree))\n",
    "    print('MAP: {}\\n'.format(m_ap))\n",
    "    print('Average response time: {} secs.'.format(stop-start))\n",
    "    print('\\n\\n')\n",
    "\n",
    "    \n",
    "print('Printing variables: \\n')\n",
    "print('m_ap_list: {} \\n'.format(m_ap_list))\n",
    "print('time_tree: {} \\n'.format(time_tree))\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Locality Sensitive Hashing (LSH)\n",
    " ---\n",
    " In this section, you will use LSH to index the database of images. LSH implementation included in OpenCV uses **bit sampling** for **Hamming distance** in order to construct the hash family and, therefore, binary descriptors should be used. Hence, SIFT descriptors are not valid and we need to describe again the images, but using, for instance, ORB.\n",
    "\n",
    " In the following cell, write the code required to generate roughly 1500 keypoints / descriptors using ORB for each query / test image:\n",
    "\n",
    " > **Useful functions**: [cv2.FlannBasedMatcher](https://docs.opencv.org/3.4/dc/de2/classcv_1_1FlannBasedMatcher.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965\n",
      "(965, 32)\n",
      "[[182 247  64 ... 214 158 220]\n",
      " [ 56 141 104 ...  43 212 234]\n",
      " [227 182 190 ...  68 239 223]\n",
      " ...\n",
      " [ 71 215 226 ... 216 177  29]\n",
      " [ 18  40 214 ...   0  41   4]\n",
      " [ 42 176  32 ...  15 155 215]]\n"
     ]
    }
   ],
   "source": [
    "query_kps_orb = []\n",
    "query_desc_orb = []\n",
    "train_kps_orb = []\n",
    "train_desc_orb = []\n",
    "\n",
    "##############################################################################\n",
    "# TODO:                                                                      #\n",
    "# Extract 1500 keypoints / descriptors from every query and test images      # \n",
    "# using ORB. Store the results in the list indicated above.                  #\n",
    "##############################################################################\n",
    "\n",
    "orb = cv2.ORB_create(nfeatures = 1500, fastThreshold = 50)\n",
    "for query in query_imgs: \n",
    "    kp,des = orb.detectAndCompute(query, mask=None)\n",
    "    query_kps_orb.append(kp)\n",
    "    query_desc_orb.append(des)\n",
    "    \n",
    "for train in train_imgs: \n",
    "    kp,des = orb.detectAndCompute(train, mask=None)\n",
    "    train_kps_orb.append(kp)\n",
    "    train_desc_orb.append(des)\n",
    "    \n",
    "##############################################################################\n",
    "#                                 END OF YOUR CODE                           #\n",
    "##############################################################################\n",
    "\n",
    "# Show some data\n",
    "print(len(query_kps_orb[0]))\n",
    "print(query_desc_orb[0].shape)\n",
    "print(query_desc_orb[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write a function to build a **standard** (*no multi-probe*) LSH index from a set of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_db_lsh(img_names, descs, tables = 6, hash_size = 12):\n",
    "    '''\n",
    "    Index a set of images using LSH.\n",
    "    \n",
    "    - img_names: An ordered list with the names of query images.\n",
    "    - descs: A list containing numpy arrays of size (~1500, 128). Each numpy array\n",
    "            i corresponds to the descriptors found at image i.\n",
    "    - tables: Number of hash tables to create.\n",
    "    - hash_size: Hash length in bits.\n",
    "\n",
    "    RETURNS: \n",
    "    - index: The trained LSH index.\n",
    "    - id_to_img: An associative list to link every index to the real name of the\n",
    "        image e.g. id_to_img[0] = '100001.jpg', id_to_img[1] = '100002.jpg'\n",
    "    '''  \n",
    "    #index = []\n",
    "    #id_to_img = []\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO:                                                                      #\n",
    "    # Write this function according to the description given above.              #\n",
    "    ##############################################################################\n",
    "    \n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm = FLANN_INDEX_LSH, table_number = tables, key_size = hash_size, multi_probe_level = 0)\n",
    "    search_params = {}  #{} \n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    start = time.time()\n",
    "    flann.add(descs)\n",
    "    flann.train()\n",
    "    stop = time.time()\n",
    "    \n",
    "    training_time = stop - start\n",
    "    ##############################################################################\n",
    "    #                                 END OF YOUR CODE                           #\n",
    "    ##############################################################################\n",
    "\n",
    "    return flann, training_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > **Questions**: Search the query images against the database using the `compute_mAP` function and the LSH index:\n",
    " >\n",
    " > - What is the mAP obtained using this approach?\n",
    " \n",
    " > <font color = 'blue'>En este caso, en lugar de buscar en un árbol binario, se busca en tablas de hash donde cada descriptor de entrenamiento es asignado a un determinado código binario empleado una función de hashing. En este caso, dicha función es el _bit sampling_ . Posteriormente, los descriptores de la imagen de petición son transformados a códigos binarios con la misma función. Cada descriptor de petición se empareja con dos descriptores de entrenamiento con el mismo código binario. De nuevo, una vez filtrados dichos emparejamientos, se realiza un conteo de las imágenes de entrenamiento correspondientes a cada descriptor emparejado con los descriptores de petición. Aquellas imágenes con mayor nñumero de descriptores emparejados con la imagen de petición se devuelven las primeras.</font> \n",
    " \n",
    " > - Is it stable? Why?\n",
    " \n",
    " > <font color = 'blue'>De nuevo, se puede decir que el sistema es estable en término de mAP. Se han realizado 3 iteraciones empleando índices contruidos con los mismos parámetros, y los mAP son casi idénticos entre iteraciones.</font>  \n",
    " \n",
    " > - Analyze the effect of changing the **number of tables** / **hash size** in terms of mAP and average response time. Some plots here can be useful to justify your answer.\n",
    " \n",
    " > Para contestantar a esta pregunta se han realizado varias pruebas con combinaciones distintas de parámetros. Se hab probado dos números distintos de tablas, 6 y 8, y dos tamaños distintos de código hash binario, 12 y 16. \n",
    " \n",
    " > <font color = 'blue'>Como puede observarse en las impresiones, por una parte se concluye que a cuantas más tablas se usen mayor es el tiempo total del proceso (entrenamiento más búsqueda de imágenes). Por otra parte, a mayor tamaño del código binario de hash empleado, mucho menor es dicho tiempo de ejecución, con una reducción entorno al 85%. En cuanto al mAP, en ambos casos es muy semejante, no hay diferencias significativas entre usar más o menos tablas o entre usar un tamaño de código más o menos grande.</font>  \n",
    " \n",
    " > - Despite the different descriptors used, compare the performance of LSH and randomized $k$-d trees from different points of view (accuracy, memory, training times, querying times, ...). Some plots here can be useful to justify your answer.\n",
    " \n",
    " > <font color = 'blue'>En esta pregunta me he centrado en analizar los tiempos de entrenamiento de cada índice y los tiempos medios de búsqueda por imagen, así como la desviación que estos presentan respecto de la media para analizar su estabilidad entre búsquedas. Para ello se han determinado estos valores para 3 iteraciones distintas con los mismos parámetros constructivos de los índices, dotando así de mayor signifiancia estadística a las conclusiones extraídas.</font> \n",
    " \n",
    " > <font color = 'blue'>Una vez dicho esto, se puede decir que el tiempo de entrenamiento de los kd-trees es mucho mayor al LSH, entorno a 6 veces más rápidos estos útlimos en entrenarse. Sin embargo, en cuanto a indexación de imágenes, se aprecia que los kd-trees son mucho más rápidos que los LSH, con tiempos 6 o 7 veces menores que estos últimos. En cuanto a la estabilidad en los tiempos de búsqueda, se observa que los kd-trees presentan desviaciones estándar proporcionalmente menores a los LSH. Esto últimos presentan desviación de casi el 50% respecto de la media. Por ello, puede decirse que en cuanto a tiempo de indexación, los kd-trees son más estables.</font> \n",
    " \n",
    " > <font color = 'blue'>Finalmente también puede realizarse una comparación de mAP. Simplemente comentar que los kd-trees obtienen valores mAP mayores que LSH. Ambos índices son igualmente estables en términos de dicha métrica.</font> \n",
    " \n",
    " > <font color = 'blue'>No se han establecido comparaciones a nivel de memoria usada por motivos de destreza técnica. No sabía cómo evaluar dicho aspecto. Aunque basándome en los conceptos teóricos de cada método, me aventuraría a decir que, pese a que ambos métodos necesitan tener todos los descriptores cargados en memoria,  los LSH emplean menos recursos que los kd-trees, ya que estos últimos emplean descriptores en coma flotante,a diferencia de los primeros que emplean descriptores binarios.</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "\n",
      "MAP: 0.5570587650087657 \n",
      "\n",
      "Training time: 0.683635950088501 secs.\n",
      "Query response time: 0.4261805658340454 +- 0.22208931480614968 secs.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "MAP: 0.5521084270410586 \n",
      "\n",
      "Training time: 0.7014031410217285 secs.\n",
      "Query response time: 0.4182029438018799 +- 0.2081014932406212 secs.\n",
      "\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "MAP: 0.5515775819022046 \n",
      "\n",
      "Training time: 0.6714541912078857 secs.\n",
      "Query response time: 0.49273929500579833 +- 0.24966283784247303 secs.\n",
      "\n",
      "\n",
      "\n",
      "Mean training time LSH: 0.6854977607727051 secs.\n",
      "Mean query response time LSH: 0.4457076015472412 secs\n",
      "Combination -> tables = 6; hash_size = 12 \n",
      "\n",
      "MAP: 0.5558477789499733\n",
      "\n",
      "Average response time: 237.3519468307495 secs.\n",
      "\n",
      "\n",
      "\n",
      "Combination -> tables = 6; hash_size = 16 \n",
      "\n",
      "MAP: 0.5568846196141212\n",
      "\n",
      "Average response time: 36.71414113044739 secs.\n",
      "\n",
      "\n",
      "\n",
      "Combination -> tables = 8; hash_size = 12 \n",
      "\n",
      "MAP: 0.553578533273073\n",
      "\n",
      "Average response time: 288.5771508216858 secs.\n",
      "\n",
      "\n",
      "\n",
      "Combination -> tables = 8; hash_size = 16 \n",
      "\n",
      "MAP: 0.5493404076574129\n",
      "\n",
      "Average response time: 54.25728797912598 secs.\n",
      "\n",
      "\n",
      "\n",
      "Printing variables: \n",
      "\n",
      "m_ap_lsh_list: [0.5558477789499733, 0.5568846196141212, 0.553578533273073, 0.5493404076574129] \n",
      "\n",
      "time_lsh: [237.3519468307495, 36.71414113044739, 288.5771508216858, 54.25728797912598] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write here the code required to answer the questions stated above. You can   #\n",
    "# Add more cells at this point if you need it.                                 #\n",
    "################################################################################\n",
    "\n",
    "mean_query_t_lsh = 0.0\n",
    "mean_train_t_lsh = 0.0\n",
    "#Stability\n",
    "for i in range(niters):\n",
    "    index_lsh, train_time_lsh = build_db_lsh(train_names, train_desc_orb, tables = 6, hash_size = 12)\n",
    "    results_lsh, m_ap_lsh, query_time_lsh = compute_mAP(query_names, query_desc_orb, index_lsh, train_names)\n",
    "    mean_query_t_lsh += np.mean(query_time_lsh)\n",
    "    mean_train_t_lsh += train_time_lsh\n",
    "    print('Iteration {}\\n'.format(i))\n",
    "    print('MAP: {} \\n'.format(m_ap_lsh))\n",
    "    print('Training time: {} secs.'.format(train_time_lsh))\n",
    "    print('Query response time: {} +- {} secs.'.format(np.mean(query_time_lsh), np.std(query_time_lsh)))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "\n",
    "print ('Mean training time LSH: {} secs.'.format(mean_train_t_lsh/niters))\n",
    "print('Mean query response time LSH: {} secs'.format(mean_query_t_lsh/niters))\n",
    "\n",
    "\n",
    "# Response time w/ different paramenters\n",
    "param_combs = [[6,12], [6,16], [8,12], [8,16]]\n",
    "m_ap_lsh_list = []\n",
    "time_lsh = []\n",
    "for comb in param_combs: \n",
    "    start = time.time()\n",
    "    index_lsh, _ = build_db_lsh(train_names, train_desc_orb, tables = comb[0], hash_size = comb[1])\n",
    "    results_lsh, m_ap_lsh, _ = compute_mAP(query_names, query_desc_orb, index_lsh, train_names)\n",
    "    stop = time.time()\n",
    "    m_ap_lsh_list.append(m_ap_lsh)\n",
    "    time_lsh.append(stop-start)\n",
    "    print('Combination -> tables = {}; hash_size = {} \\n'.format(comb[0], comb[1]))\n",
    "    print('MAP: {}\\n'.format(m_ap_lsh))\n",
    "    print('Average response time: {} secs.'.format(stop-start))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    \n",
    "print('Printing variables: \\n')\n",
    "print('m_ap_lsh_list: {} \\n'.format(m_ap_lsh_list))\n",
    "print('time_lsh: {} \\n'.format(time_lsh))\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Bag of Words (BoW)\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Download Visual Dictionaries\n",
    " To use a BoW model, first we need a visual vocabulary. The authors of the INRIA Holidays dataset provide some visual vocabularies, trained using a clustering method (like $k$-means) in a different dataset (Flickr60K).\n",
    "\n",
    " First, let's download these vocabulary files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A folder named *clust* is now available in your workspace, containing visual vocabularies of 100, 200, 500, 1K, 2K, 5K, 10K, 20K, 50K, 100K and 200K visual words. Again, these are binary files, and therefore we provide you with functions to load and index them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = iu.load_visual_vocab(\"clust/clust_flickr60_k200.fvecs\", ntrees=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With this function, the corresponding vocabulary is read and, additionally, a FLANN index structure based on kd-trees is built and returned. This is to allow a fast access when searching for the closest visual words in the vocabulary. More precisely, in this example, 4 trees are constructed using the 200 centroids. Now, given a query descriptor(s), you can use `match` or `knnMatch` methods as usual to search for the closest visual words in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### BoW and Inverted File\n",
    " Now, write a class called `BoW` to manage the indexing procedure. This class should make use, in addition to the visual vocabulary, an inverted file to compute similarity scores between images. Apart from the class constructor, write two methods, `build_index` and `search_image`, to build the index using a set of train images and to search a query image in the database, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoW(object):\n",
    "    '''\n",
    "    Class to implement the BoW model + Inverted File.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, vocab_file):\n",
    "        '''\n",
    "        Class constructor. You should load the vocabulary and initialize other stuff\n",
    "        required for the CBIR system, such as the inverted file structure.\n",
    "        '''\n",
    "        self.vocab = iu.load_visual_vocab(vocab_file)\n",
    "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
    "        \n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Complete this function as indicated                                      #\n",
    "        ############################################################################\n",
    "        init_dict = [(str(i), []) for i in range(self.nwords)] \n",
    "        self.inverted = dict(init_dict)\n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n",
    "\n",
    "    def build_index(self, img_names, img_descs):\n",
    "        '''\n",
    "        Build an index from a set of images. Essentially, for each image, you should\n",
    "            search its descriptors in the index and fill the inverted file structure\n",
    "            in consequence.\n",
    "\n",
    "        - img_names: An ordered list with the names of the train images.\n",
    "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
    "            to the descriptors found at image i.\n",
    "        '''\n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Write this function according to the description given above.            #\n",
    "        ############################################################################\n",
    "        start = time.time()\n",
    "        for name, descs in zip(img_names, img_descs): \n",
    "            matches = self.vocab.match(descs)\n",
    "            idxs = [match.trainIdx for match in matches]\n",
    "            idxs_u = np.unique(np.array(idxs)) #para evitar imagenes repetidas en el inverted file\n",
    "            for idx in list(idxs_u):\n",
    "                self.inverted[str(idx)].append(name)\n",
    "        stop = time.time()\n",
    "        training_time = stop-start\n",
    "        \n",
    "        return training_time\n",
    "    \n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n",
    "\n",
    "    def search_image(self, descs):\n",
    "        '''\n",
    "        Search an image in the index.\n",
    "    \n",
    "        - descs: A numpy array. It is the set descriptors extracted \n",
    "            from the query image.\n",
    "\n",
    "        RETURNS:\n",
    "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "        '''\n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Write this function according to the description given above.            #\n",
    "        ############################################################################\n",
    "        \n",
    "        start = time.time()\n",
    "        matches = self.vocab.match(descs)\n",
    "        idxs = [match.trainIdx for match in matches]\n",
    "        counter = {}\n",
    "        for idx in idxs: \n",
    "            retrieved_imgs = self.inverted[str(idx)]\n",
    "            for ret_img in retrieved_imgs: \n",
    "                if ret_img not in list(counter.keys()): \n",
    "                    #counter.setdefault(ret_img, 1) #creo la entrada con valor 1\n",
    "                    counter[ret_img] = 1\n",
    "                else: \n",
    "                    counter[ret_img] += 1\n",
    "        \n",
    "        values = np.array(list(counter.values()))\n",
    "        imgs_names = list(counter.keys())\n",
    "        index_sort = np.argsort(values)[::-1] #descending order \n",
    "        best_imgs = [imgs_names[i] for i in index_sort]\n",
    "        stop = time.time()\n",
    "        query_time = stop-start\n",
    "        \n",
    "        return best_imgs, query_time\n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, as usual, write a function called `compute_mAP` to the compute the performance of the system, given a lists of query images. This function should return a Python dictionary with the ordered results for each query along with the computed mAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(query_names, query_descs, index, gt_file = 'holidays/holidays_images.dat'):\n",
    "    '''\n",
    "    Perform a search for a list of query images against the database and evaluates\n",
    "    the performance of the system.\n",
    "    \n",
    "    - query_names: An ordered list with the names of query images.\n",
    "    - query_descs: A list containing numpy arrays of size \n",
    "            (ndesc_for_this_image, 128). Each numpy array i corresponds to the \n",
    "            descriptors found at image i.\n",
    "    - index: Index to search.\n",
    "    - gt_file = Ground truth file. Typically, 'holidays_images.dat'.\n",
    "\n",
    "    RETURNS: \n",
    "    - total_results: A dictionary containing, for each query image, \n",
    "            an ordered list of the retrieved images.\n",
    "    - m_ap: Mean Average Precision averaged over all queries.\n",
    "    '''\n",
    "    total_results = {}\n",
    "    m_ap = 0.0\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO:                                                                      #\n",
    "    # Write this function according to the description given above.              #\n",
    "    ##############################################################################\n",
    "    query_times = []\n",
    "    for query_name, query_desc in zip(query_names, query_descs):\n",
    "            results, query_time = index.search_image(query_desc)\n",
    "            total_results[query_name] = results \n",
    "            query_times.append(query_time)\n",
    "        \n",
    "    m_ap = ev.compute_mAP(total_results, gt_file)\n",
    "    \n",
    "    ##############################################################################\n",
    "    #                                 END OF YOUR CODE                           #\n",
    "    ##############################################################################\n",
    "    \n",
    "    return total_results, m_ap, np.array(query_times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using the vocabularies of 200, 2K, 20K and 200K visual words, answer the following questions:\n",
    " > **Questions**:\n",
    " >\n",
    " > - What is the mAP obtained for each visual vocabulary?\n",
    " \n",
    " > <font color = 'blue'>En este caso, cada descriptor de la imagen de petición se emparejado con una palabra visual. Esta palabra visual no es nada más que un descriptor \"abstracto\" fruto del proceso de clustering en un espacio de descriptores provenientes de imágenes de entrenamiento. En esta caso concreto, estas imágenes de entrenameinto provienen del dataset Flickr60. Cada palabra visual guarda un registro de aquellas imágenes que contienen dicha palabra visual en una archivo llamado fichero inverso. Así pues, por cada descriptor de petición se registran o se lleva la cuenta de aquellas imágenes enlazadas con la palabra visual emparejada a dicho descriptor. Aquellas imágenes que han aparecido con más frecuencia se retornan las primeras.</font> \n",
    " \n",
    " > - Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?\n",
    " \n",
    " > <font color = 'blue'>En este caso, a mayor número de palabras visuales contiene el diccionario, mejor mAP se obtiene. Además, se observa que los tiempo de petición también disminuyen considerablemente a cuantas más palabras se tengan. Sin embargo, el tiempo de entrenamiento del índice aumenta en este caso. No obstante, esta fase puede hacerse de manera offline, por lo que no condiciona al rendimiento en real-time del modelo. Es por ello que, ateniéndome a este caso particular, sí que parece beneficioso el hecho de usar más palabras en el diccionario en todos los aspectos.  Aun así, en aplicaciones donde los recursos de memoria sean limitados, el uso de un diccionario muy extenso podría no ser factible. Además, vocabularios muy extensos podrían incurrir en problemas de sobreajuste, generando descriptores muy especificos y perdiendo así la esencia del modelo BoW. </font> \n",
    " \n",
    " > <font color = 'blue'>Llegados a este punto me gustaría comentar un aspecto importante. El diccionario con 200 palabras tarda un tiempo medio de indexación o busqueda (query_time) de alrededor de 11 segundos. Esto multiplicado por 500 imágenes de query son 5500 segundos, es decir, 90 minutos aproximadamente. Esto ha provocado que la ejecución de este modelo sea muy larga, tardando en torno a 2 horas. Esto es debido a que el tamaño del índice no es lo suficientemente grande como para generar unas listas de imágenes más dispersas. Así pues, se crea una gran acumulación de imágenes por palabra visual y se tarda más en procesar dicha información.</font> \n",
    " \n",
    " > - Analyze the effect of the **vocabulary_size** in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer.\n",
    " \n",
    " > <font color = 'blue'>Como ya se ha comentado, a cuantas más palabras tenga el vocabulario, mejor mAP se obtiene. También se ha comentado que a cuantas más palabras, menor es el tiempo de query o indexación requerido. No obstante, mayor es el tiempo de entrenamiento también.</font> \n",
    " \n",
    " > <font color = 'blue'>En cuanto a la estabilidad en los tiempos de indexación, a mayor número de palabras más estable son los tiempos. Esto se ve reflejado en la desviación estándar de dichos tiempos. En el primer caso, con 200 palabras, la desviación estándar se situa en torno a un 35% respecto de la media. Este valor decrece monótonamente haste el último caso, con 200k palabras, donde esta se siua en torno al 27%.</font> \n",
    " \n",
    " > - Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?\n",
    " \n",
    " > <font color = 'blue'>Los resultados sí que se pueden ver afectados por el conjunto de imágenes empleado para generar las palabras visuales. Como ya se ha comentado, las palabras visuales se crear a partir de un proceso de clustering en el espacio de descriptores del conjunto de entrenamiento. Otro conjunto distinto de entrenamiento daría lugar a palabras distintas y por ende a un fichero inverso distinto. Ello concluiría con resultados distintos el la búsqueda de imágenes.</font> \n",
    " \n",
    " > <font color = 'blue'>Para mejorar el rendimiento de la búsqueda, se podrían generar palabras usando imágenes muy parecidas en contexto al caso particular de uso de este sistema. Es decir, si se sabe que las imágenes que se van a buscar son imágenes de bosques y playas, generar un vocabulario usando este tipo de imágenes. Sin embargo, ello desembocaría posiblemente en un sobreajuste del modelo. Si se quiere un vocabulario más genérico, lo ideal es generarlo con una gran cantidad de imágenes diversas, reflejando así la variedad de información existente, y con un número de palabras suficiente como para plasmar dicha variedad de información sin caer en un sobreajuste del modelo.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of 200: \n",
      "\n",
      "MAP: 0.04831850557132996 \n",
      "\n",
      "Training time: 11.336090087890625 secs.\n",
      "Query time: 11.279020719051362 +- 3.2623391381912263 secs.\n",
      "\n",
      "\n",
      "\n",
      "Vocabulary size of 2000: \n",
      "\n",
      "MAP: 0.4230062621759219 \n",
      "\n",
      "Training time: 11.315753936767578 secs.\n",
      "Query time: 4.207218329429627 +- 1.2884616408542982 secs.\n",
      "\n",
      "\n",
      "\n",
      "Vocabulary size of 20000: \n",
      "\n",
      "MAP: 0.4595130696784457 \n",
      "\n",
      "Training time: 16.377777099609375 secs.\n",
      "Query time: 0.8069303660392761 +- 0.2611327911529182 secs.\n",
      "\n",
      "\n",
      "\n",
      "Vocabulary size of 200000: \n",
      "\n",
      "MAP: 0.522391190501858 \n",
      "\n",
      "Training time: 21.18097186088562 secs.\n",
      "Query time: 0.11888259220123291 +- 0.040282420877753425 secs.\n",
      "\n",
      "\n",
      "\n",
      "Printing variables: \n",
      "\n",
      "m_ap_bow: [0.04831850557132996, 0.4230062621759219, 0.4595130696784457, 0.522391190501858] \n",
      "\n",
      "train_time_bow: [11.336090087890625, 11.315753936767578, 16.377777099609375, 21.18097186088562] \n",
      "\n",
      "query_times_bow: [array([1.33781319e+01, 1.32177501e+01, 1.32065809e+01, 1.28959942e+01,\n",
      "       1.27883551e+01, 1.52837741e+01, 1.30957990e+01, 1.30187941e+01,\n",
      "       1.28065212e+01, 9.26806021e+00, 7.28120327e+00, 1.26789801e+01,\n",
      "       1.30191841e+01, 2.64512062e-01, 2.82783508e+00, 1.23825827e+01,\n",
      "       8.66237402e+00, 1.38481889e+01, 1.35701160e+01, 1.30692012e+01,\n",
      "       1.36046450e+01, 1.31877720e+01, 1.19294252e+01, 1.29590058e+01,\n",
      "       1.28783069e+01, 1.30596979e+01, 1.29243331e+01, 1.19012690e+01,\n",
      "       1.28869059e+01, 1.28757844e+01, 1.21680870e+01, 1.31781712e+01,\n",
      "       1.23791561e+01, 1.20238898e+01, 1.31619840e+01, 1.28940630e+01,\n",
      "       1.30069401e+01, 1.32070751e+01, 1.36569340e+01, 1.31589158e+01,\n",
      "       1.33890409e+01, 1.36211209e+01, 3.02014589e+00, 1.18925920e+01,\n",
      "       1.25491230e+01, 1.26435001e+01, 1.30526092e+01, 1.30969710e+01,\n",
      "       1.29367480e+01, 1.26035268e+01, 1.30038879e+01, 1.26760228e+01,\n",
      "       1.26807411e+01, 1.35344982e+01, 1.25413072e+01, 1.32841852e+01,\n",
      "       1.31995962e+01, 9.11790633e+00, 1.29476500e+01, 1.23394380e+01,\n",
      "       1.19429591e+01, 1.27382553e+01, 1.29426720e+01, 1.25932970e+01,\n",
      "       1.29071920e+01, 1.25678248e+01, 6.77695298e+00, 1.24788139e+01,\n",
      "       1.30175459e+01, 1.32759731e+01, 1.31938570e+01, 1.30131528e+01,\n",
      "       1.32919300e+01, 1.24653692e+01, 1.31391847e+01, 1.35089121e+01,\n",
      "       1.36479974e+01, 2.14593410e+00, 6.21721387e+00, 9.43492174e-01,\n",
      "       9.39087009e+00, 9.15997171e+00, 5.30582285e+00, 1.24402089e+01,\n",
      "       1.21339941e+01, 1.28068349e+01, 1.25283163e+01, 1.28271902e+01,\n",
      "       1.32314632e+01, 1.30750580e+01, 3.65205693e+00, 1.28867269e+01,\n",
      "       1.21184931e+01, 1.28826859e+01, 1.27340412e+01, 1.23385139e+01,\n",
      "       1.26417992e+01, 1.28533230e+01, 1.27786400e+01, 1.24656858e+01,\n",
      "       1.27615380e+01, 1.26463180e+01, 1.26493299e+01, 1.31289201e+01,\n",
      "       1.28689971e+01, 1.26686292e+01, 1.31471250e+01, 1.28451910e+01,\n",
      "       1.32612541e+01, 1.20346110e+01, 1.29550288e+01, 1.28586009e+01,\n",
      "       1.25608420e+01, 4.33269596e+00, 9.18185592e+00, 2.92562103e+00,\n",
      "       1.28409827e+01, 1.29807031e+01, 1.31058512e+01, 1.26641309e+01,\n",
      "       1.29240990e+01, 1.29660189e+01, 1.31158090e+01, 1.30129862e+01,\n",
      "       1.25656710e+01, 1.22756197e+01, 1.26561139e+01, 1.26792741e+01,\n",
      "       1.23646719e+01, 1.23951957e+01, 1.26780980e+01, 1.24169052e+01,\n",
      "       1.00833583e+00, 7.85880303e+00, 1.18251750e+01, 1.27633131e+01,\n",
      "       1.28996007e+01, 1.27226589e+01, 1.27611098e+01, 1.26229610e+01,\n",
      "       1.21612380e+01, 1.26784551e+01, 1.29235270e+01, 2.75880623e+00,\n",
      "       1.27244670e+01, 1.25253460e+01, 1.30611870e+01, 1.36710000e+01,\n",
      "       1.26563258e+01, 1.25646393e+01, 2.35904002e+00, 1.27477660e+01,\n",
      "       1.26311240e+01, 1.17306979e+01, 1.22050731e+01, 1.27939451e+01,\n",
      "       1.24805439e+01, 1.26861441e+01, 1.30663209e+01, 1.28585017e+01,\n",
      "       1.27415812e+01, 1.29271910e+01, 1.26013198e+01, 1.27473862e+01,\n",
      "       1.28745480e+01, 9.14046597e+00, 1.26756659e+01, 1.22908819e+01,\n",
      "       1.29607310e+01, 1.31044900e+01, 1.28949761e+01, 1.24146740e+01,\n",
      "       1.28222873e+01, 5.91223311e+00, 1.25647531e+01, 1.26777830e+01,\n",
      "       1.30168941e+01, 1.28273659e+01, 1.23457408e+01, 1.28194730e+01,\n",
      "       1.29970000e+01, 1.30617409e+01, 1.27412128e+01, 1.20490663e+01,\n",
      "       1.28241789e+01, 1.25677052e+01, 9.75989890e+00, 7.24982882e+00,\n",
      "       8.63889694e+00, 1.25245512e+01, 1.25389397e+01, 1.28439980e+01,\n",
      "       1.28255780e+01, 1.27491510e+01, 1.22318280e+01, 1.28512368e+01,\n",
      "       1.27771599e+01, 1.26061866e+01, 1.22653091e+01, 1.30694861e+01,\n",
      "       1.28762333e+01, 1.27052710e+01, 1.31049020e+01, 1.29155991e+01,\n",
      "       1.24301839e+01, 1.26246731e+01, 1.26855230e+01, 1.27742410e+01,\n",
      "       1.28450680e+01, 1.25343161e+01, 1.25496519e+01, 1.27576351e+01,\n",
      "       1.24987400e+01, 1.25369511e+01, 1.27737861e+01, 1.21626458e+01,\n",
      "       1.25041800e+01, 1.31886010e+01, 1.08034148e+01, 1.30837979e+01,\n",
      "       1.26815381e+01, 1.24997530e+01, 1.28752122e+01, 1.27085238e+01,\n",
      "       1.32793188e+01, 1.25362267e+01, 1.25097029e+01, 1.27644801e+01,\n",
      "       1.24392767e+01, 1.22787459e+01, 1.25537181e+01, 1.30086269e+01,\n",
      "       1.37121091e+01, 1.30947750e+01, 1.23194990e+01, 1.25724602e+01,\n",
      "       1.24987988e+01, 1.21359439e+01, 1.28593781e+01, 1.26316330e+01,\n",
      "       1.24066241e+01, 9.75284386e+00, 1.23522248e+01, 1.23737977e+01,\n",
      "       1.17000911e+01, 1.23557842e+01, 1.28759968e+01, 1.28965361e+01,\n",
      "       9.09336090e-01, 1.00787990e+01, 1.25431919e+01, 1.33806071e+01,\n",
      "       1.27398121e+01, 1.14390359e+01, 9.92394590e+00, 1.24484689e+01,\n",
      "       1.32237189e+01, 8.98391247e-01, 2.59876251e-05, 1.22805948e+01,\n",
      "       1.31058049e+01, 1.31143649e+01, 1.27245610e+01, 5.66803193e+00,\n",
      "       1.26790171e+01, 1.25825250e+01, 8.15981388e+00, 6.20872402e+00,\n",
      "       1.12473321e+00, 1.25089889e+01, 7.29826617e+00, 1.31275320e+01,\n",
      "       6.29379797e+00, 9.94561696e+00, 3.37003708e-01, 5.01485181e+00,\n",
      "       2.56244707e+00, 5.39950848e-01, 1.26163549e+01, 9.86862183e-02,\n",
      "       1.28780150e+01, 1.28746653e+01, 1.25754960e+01, 6.24228239e-01,\n",
      "       1.23046708e+01, 1.31544080e+01, 1.24620328e+01, 1.23077798e+01,\n",
      "       6.49116182e+00, 1.25325370e+01, 1.27151780e+01, 1.21918488e+01,\n",
      "       1.24395642e+01, 4.04612613e+00, 3.67898703e+00, 1.12590504e+00,\n",
      "       5.55891466e+00, 1.24154344e+01, 1.25393679e+01, 1.26282239e+01,\n",
      "       6.53017187e+00, 1.00332022e+00, 1.29722271e+01, 1.31925170e+01,\n",
      "       1.30518620e+01, 1.25544808e+01, 4.85898280e+00, 1.25079949e+01,\n",
      "       1.27119040e+01, 1.28964040e+01, 1.27551162e+01, 1.24894421e+01,\n",
      "       1.25795710e+01, 9.21374798e-01, 1.27814610e+01, 1.28972831e+01,\n",
      "       2.14794993e+00, 1.29031618e+01, 1.26498451e+01, 8.11034584e+00,\n",
      "       2.32702112e+00, 1.25041258e+01, 1.04697108e+00, 1.30659490e+01,\n",
      "       1.28852839e+01, 9.42222524e+00, 1.20975220e+01, 8.40198684e+00,\n",
      "       6.59338427e+00, 1.27025189e+01, 1.25295670e+01, 1.27838871e+01,\n",
      "       1.29327180e+01, 1.27527819e+01, 1.26481109e+01, 1.29256990e+01,\n",
      "       5.68828082e+00, 1.34010561e+01, 1.30925629e+01, 1.28200061e+01,\n",
      "       1.31601179e+01, 1.24916110e+01, 1.21120148e+01, 1.25889540e+01,\n",
      "       1.33727102e+01, 1.29839811e+01, 1.28090179e+01, 1.36057799e+01,\n",
      "       1.34045191e+01, 2.73412681e+00, 1.31598279e+01, 1.38288410e+01,\n",
      "       1.26719539e+01, 1.28805890e+01, 1.29493346e+01, 1.28651249e+01,\n",
      "       1.32935030e+01, 1.33078902e+01, 1.28353469e+01, 1.27913020e+01,\n",
      "       1.30171759e+01, 1.33887620e+01, 1.29648232e+01, 1.27544823e+01,\n",
      "       1.31952751e+01, 1.24866250e+01, 1.27308369e+01, 1.30192969e+01,\n",
      "       1.35408239e+01, 1.27862232e+01, 1.24173319e+01, 1.08908670e+01,\n",
      "       1.27791669e+01, 4.41447496e+00, 1.18256290e+01, 1.31607692e+01,\n",
      "       1.21257100e+01, 1.22443721e+01, 1.23575401e+01, 1.25902441e+01,\n",
      "       1.29082417e+01, 2.35591316e+00, 1.26040888e+01, 9.36190701e+00,\n",
      "       1.25390911e+01, 7.09734607e+00, 7.86606503e+00, 8.88952875e+00,\n",
      "       4.81440306e+00, 1.28941524e+01, 1.31774621e+01, 6.32633018e+00,\n",
      "       8.52060199e+00, 1.29228497e+00, 3.79061103e+00, 5.30027699e+00,\n",
      "       1.25912371e+01, 2.69669795e+00, 3.50154090e+00, 1.27414379e+01,\n",
      "       3.70414424e+00, 1.23937080e+01, 1.28356462e+01, 1.29487281e+01,\n",
      "       1.24439890e+01, 1.24539912e+01, 1.33227551e+01, 1.28713727e+01,\n",
      "       1.24890189e+01, 1.23138251e+01, 1.23491700e+01, 1.24615769e+01,\n",
      "       1.21179173e+01, 1.25122199e+01, 1.28185937e+01, 1.25623770e+01,\n",
      "       1.18919139e+01, 1.33086152e+01, 1.28628271e+01, 1.27302470e+01,\n",
      "       2.24880528e+00, 1.25029347e+01, 1.30043738e+01, 1.23244009e+01,\n",
      "       1.27725739e+01, 1.24234629e+01, 1.28462760e+01, 4.30808401e+00,\n",
      "       1.01754539e+01, 8.81409574e+00, 1.24060991e+01, 1.31100760e+01,\n",
      "       1.25313950e+01, 1.22171719e+01, 2.48327494e+00, 1.11178741e+01,\n",
      "       2.61372399e+00, 7.50127625e+00, 8.58288622e+00, 7.29001808e+00,\n",
      "       1.09730990e+01, 1.24642863e+01, 1.31424999e+00, 6.10392404e+00,\n",
      "       1.23016381e+01, 1.26444068e+01, 1.24304969e+01, 1.24284019e+01,\n",
      "       7.48326302e+00, 1.17834172e+01, 8.47587991e+00, 1.30209520e+01,\n",
      "       1.23196750e+01, 1.23920140e+01, 1.29407220e+01, 1.25605257e+01,\n",
      "       1.27552948e+01, 1.33737810e+01, 1.32318180e+01, 1.21989954e+01,\n",
      "       1.26374230e+01, 1.25741289e+01, 1.21496730e+01, 7.64809084e+00,\n",
      "       1.28185458e+01, 1.29809201e+01, 1.20236783e+01, 1.20799701e+01,\n",
      "       1.29252350e+01, 1.22072182e+01, 1.25938501e+01, 1.26042662e+01,\n",
      "       1.28540211e+01, 1.28652570e+01, 1.30073061e+01, 6.86141109e+00,\n",
      "       1.27778130e+01, 1.28826029e+01, 1.26120200e+01, 4.27665734e+00,\n",
      "       1.23244691e+01, 1.33429580e+01, 6.20001984e+00, 1.22510021e+01,\n",
      "       1.24608641e+01, 1.24653780e+01, 8.56242776e+00, 1.21460540e+01,\n",
      "       1.24808969e+01, 1.21194742e+01, 1.25396669e+01, 1.23279650e+01,\n",
      "       1.28913081e+01, 1.25918231e+01, 1.31176729e+01, 1.25371263e+01,\n",
      "       1.26760068e+01, 1.28164561e+01, 1.27860560e+01, 1.19897418e+01]), array([4.65528965e+00, 5.28751993e+00, 5.33328009e+00, 4.85335922e+00,\n",
      "       4.96023798e+00, 4.57205391e+00, 5.15994287e+00, 5.27179480e+00,\n",
      "       4.91786027e+00, 3.41494298e+00, 2.67783380e+00, 4.51160479e+00,\n",
      "       4.67956114e+00, 7.73718357e-02, 8.38019133e-01, 4.37753773e+00,\n",
      "       3.01353192e+00, 5.64930987e+00, 5.59612894e+00, 4.59141994e+00,\n",
      "       4.99614286e+00, 5.20485330e+00, 3.98360395e+00, 5.03835607e+00,\n",
      "       4.88218284e+00, 5.30970478e+00, 4.98957324e+00, 3.64068818e+00,\n",
      "       4.53451109e+00, 4.58242631e+00, 4.07486796e+00, 5.07362890e+00,\n",
      "       4.58275580e+00, 4.14342570e+00, 5.37441802e+00, 4.73781919e+00,\n",
      "       5.07465696e+00, 5.30613613e+00, 6.09320593e+00, 5.09810400e+00,\n",
      "       5.53526998e+00, 5.87575412e+00, 9.38534975e-01, 4.04370189e+00,\n",
      "       4.54607606e+00, 4.39585090e+00, 5.12843204e+00, 5.38639188e+00,\n",
      "       4.67438006e+00, 4.71317601e+00, 5.03757215e+00, 4.61829925e+00,\n",
      "       4.56984591e+00, 4.79535675e+00, 4.42309713e+00, 5.52508092e+00,\n",
      "       5.11100316e+00, 3.61069107e+00, 5.06799912e+00, 4.62319493e+00,\n",
      "       4.01605105e+00, 4.90033889e+00, 5.04695392e+00, 4.53536892e+00,\n",
      "       5.01689982e+00, 4.70661616e+00, 2.22764277e+00, 4.28999114e+00,\n",
      "       4.99095011e+00, 5.30625606e+00, 5.29790688e+00, 4.94036007e+00,\n",
      "       5.42203331e+00, 4.35437012e+00, 5.45169020e+00, 6.10077596e+00,\n",
      "       5.72892475e+00, 7.75542974e-01, 2.71521091e+00, 3.54100943e-01,\n",
      "       3.36819196e+00, 3.25127220e+00, 1.98998594e+00, 4.48046112e+00,\n",
      "       4.45642185e+00, 4.55720782e+00, 4.54592276e+00, 4.84376073e+00,\n",
      "       5.62677193e+00, 5.02193618e+00, 1.47501016e+00, 4.81260800e+00,\n",
      "       4.40396500e+00, 4.97419906e+00, 4.57436180e+00, 4.60693812e+00,\n",
      "       4.39564800e+00, 4.98421812e+00, 4.45901513e+00, 4.40087128e+00,\n",
      "       4.80386305e+00, 4.77189398e+00, 4.59542179e+00, 5.14996815e+00,\n",
      "       4.78465819e+00, 4.64982605e+00, 4.43626690e+00, 4.31409836e+00,\n",
      "       5.28865790e+00, 4.33781075e+00, 5.00218081e+00, 4.78105807e+00,\n",
      "       4.54389906e+00, 1.41497707e+00, 3.75178003e+00, 1.22015810e+00,\n",
      "       4.88016367e+00, 4.90667200e+00, 5.28769779e+00, 4.66615105e+00,\n",
      "       5.10058284e+00, 4.79093885e+00, 5.39066696e+00, 5.03942990e+00,\n",
      "       4.50266528e+00, 4.18048692e+00, 4.58839917e+00, 4.75409198e+00,\n",
      "       4.78170228e+00, 4.39054799e+00, 4.86179304e+00, 4.24917197e+00,\n",
      "       4.38097954e-01, 3.00691390e+00, 4.11756372e+00, 5.01452637e+00,\n",
      "       4.80516505e+00, 4.46915388e+00, 4.82327199e+00, 4.72363687e+00,\n",
      "       4.34258771e+00, 4.60312796e+00, 5.18010402e+00, 9.15151834e-01,\n",
      "       4.86079621e+00, 4.76251507e+00, 4.82179809e+00, 4.95061803e+00,\n",
      "       4.29905105e+00, 5.20539498e+00, 7.99562216e-01, 4.79816484e+00,\n",
      "       4.78233719e+00, 4.88924479e+00, 4.46477795e+00, 4.79383302e+00,\n",
      "       4.45819974e+00, 4.89757609e+00, 5.13256216e+00, 4.78342319e+00,\n",
      "       4.91148686e+00, 4.97953582e+00, 4.53185391e+00, 5.15797305e+00,\n",
      "       4.73854613e+00, 3.50426292e+00, 4.66135597e+00, 4.29410696e+00,\n",
      "       4.71095610e+00, 5.26918507e+00, 4.61097693e+00, 4.53398514e+00,\n",
      "       5.09513712e+00, 1.93904996e+00, 4.48151898e+00, 4.64070392e+00,\n",
      "       5.14319897e+00, 4.79494405e+00, 4.44506884e+00, 4.88430810e+00,\n",
      "       5.04521680e+00, 5.21813107e+00, 4.88068414e+00, 3.95302200e+00,\n",
      "       4.94623804e+00, 4.55648303e+00, 3.34832406e+00, 2.68204594e+00,\n",
      "       3.18905711e+00, 4.51407409e+00, 4.47440290e+00, 4.88063002e+00,\n",
      "       5.20061278e+00, 4.86805677e+00, 4.27494979e+00, 4.89213800e+00,\n",
      "       4.89774990e+00, 4.65173602e+00, 4.18573499e+00, 5.09526730e+00,\n",
      "       4.34792185e+00, 4.29256916e+00, 5.06066823e+00, 5.07802796e+00,\n",
      "       4.44123316e+00, 4.54556489e+00, 4.85690594e+00, 4.85302401e+00,\n",
      "       4.92086077e+00, 4.70806623e+00, 4.51116204e+00, 4.70794320e+00,\n",
      "       4.54459381e+00, 4.57944107e+00, 4.96345592e+00, 4.14338493e+00,\n",
      "       4.56191206e+00, 5.75758815e+00, 3.98714399e+00, 5.09797287e+00,\n",
      "       4.56929088e+00, 4.48453903e+00, 4.91325998e+00, 4.68688607e+00,\n",
      "       5.26229978e+00, 4.60688901e+00, 4.49915218e+00, 4.79503727e+00,\n",
      "       4.43106103e+00, 4.62274933e+00, 4.39851594e+00, 5.04757881e+00,\n",
      "       5.20637894e+00, 4.73278689e+00, 4.45774198e+00, 4.41100192e+00,\n",
      "       4.40191793e+00, 4.20594811e+00, 4.81513786e+00, 4.55626082e+00,\n",
      "       4.24634600e+00, 3.40682292e+00, 4.12416792e+00, 4.24297690e+00,\n",
      "       3.70942116e+00, 4.64175320e+00, 4.96271515e+00, 5.01204586e+00,\n",
      "       3.35464954e-01, 3.81142592e+00, 4.70571017e+00, 6.12466884e+00,\n",
      "       4.84417677e+00, 4.28007007e+00, 3.84278989e+00, 4.43183088e+00,\n",
      "       5.39166808e+00, 3.34833860e-01, 2.62260437e-05, 4.21404910e+00,\n",
      "       4.63656569e+00, 5.14691687e+00, 4.95108891e+00, 2.21257496e+00,\n",
      "       4.84115100e+00, 4.59692907e+00, 3.07589698e+00, 2.03370404e+00,\n",
      "       4.02325869e-01, 4.48359823e+00, 2.55858207e+00, 5.27479506e+00,\n",
      "       2.09399414e+00, 3.72597408e+00, 1.22707844e-01, 1.67714810e+00,\n",
      "       8.15718889e-01, 2.21608877e-01, 4.46486092e+00, 2.58569717e-02,\n",
      "       4.94843817e+00, 5.03427696e+00, 4.80017304e+00, 2.20615864e-01,\n",
      "       4.24858618e+00, 5.66272187e+00, 4.09944916e+00, 4.40219402e+00,\n",
      "       2.43556404e+00, 4.61135221e+00, 4.59017992e+00, 4.05263805e+00,\n",
      "       4.50588107e+00, 1.42729712e+00, 1.31347203e+00, 4.32813168e-01,\n",
      "       2.16627693e+00, 4.40605688e+00, 4.29246473e+00, 4.29308891e+00,\n",
      "       2.54446101e+00, 3.64696026e-01, 4.95175815e+00, 5.28019881e+00,\n",
      "       4.98879313e+00, 4.62858915e+00, 1.64102912e+00, 4.19815898e+00,\n",
      "       4.83566213e+00, 4.71820307e+00, 4.63844419e+00, 4.21854591e+00,\n",
      "       4.76141906e+00, 3.13600779e-01, 4.96341205e+00, 4.88633490e+00,\n",
      "       8.72620106e-01, 4.86081815e+00, 5.07072592e+00, 2.96796393e+00,\n",
      "       7.91957140e-01, 4.27524376e+00, 4.91281748e-01, 5.18373013e+00,\n",
      "       5.05923891e+00, 3.80568123e+00, 4.08670282e+00, 2.89892387e+00,\n",
      "       2.46721673e+00, 5.01135206e+00, 4.33589721e+00, 4.57266402e+00,\n",
      "       5.01354194e+00, 4.78414893e+00, 4.29730105e+00, 4.82620430e+00,\n",
      "       2.23322892e+00, 5.54207182e+00, 5.18294883e+00, 4.89600420e+00,\n",
      "       5.22495413e+00, 4.21554804e+00, 4.19501424e+00, 4.62863207e+00,\n",
      "       5.56805301e+00, 4.79961705e+00, 4.53479099e+00, 6.03969502e+00,\n",
      "       5.49283123e+00, 1.07927990e+00, 5.54662299e+00, 6.56450725e+00,\n",
      "       4.50110579e+00, 5.06594372e+00, 4.92798495e+00, 4.84041214e+00,\n",
      "       5.26727605e+00, 5.63008213e+00, 4.83449411e+00, 4.96283293e+00,\n",
      "       4.98057890e+00, 5.71334028e+00, 4.96224785e+00, 4.81403017e+00,\n",
      "       5.21548820e+00, 4.79816914e+00, 4.66928911e+00, 5.22609591e+00,\n",
      "       6.06162286e+00, 4.66757989e+00, 4.47932005e+00, 4.46228886e+00,\n",
      "       4.93280983e+00, 1.51214194e+00, 4.07295585e+00, 5.50022888e+00,\n",
      "       4.30656791e+00, 4.03479505e+00, 4.21385980e+00, 4.52291203e+00,\n",
      "       5.20371461e+00, 8.94179106e-01, 4.50171018e+00, 3.37812519e+00,\n",
      "       4.58843923e+00, 2.56615663e+00, 2.85686707e+00, 3.18095613e+00,\n",
      "       1.84874487e+00, 5.09704423e+00, 5.50866771e+00, 2.25125027e+00,\n",
      "       2.97226691e+00, 4.14598942e-01, 1.22563291e+00, 1.86974788e+00,\n",
      "       4.75239110e+00, 8.14422131e-01, 1.24180889e+00, 4.77481699e+00,\n",
      "       1.23480678e+00, 4.42946100e+00, 4.50972915e+00, 4.87743998e+00,\n",
      "       4.34847379e+00, 4.56348300e+00, 5.85610914e+00, 4.90193939e+00,\n",
      "       4.57376623e+00, 4.54105210e+00, 4.26398277e+00, 4.44346595e+00,\n",
      "       4.27370906e+00, 4.49369717e+00, 4.80078697e+00, 4.71250010e+00,\n",
      "       3.82147384e+00, 5.59074426e+00, 4.75338793e+00, 4.82592201e+00,\n",
      "       9.48006153e-01, 4.37550807e+00, 5.05660486e+00, 4.51257706e+00,\n",
      "       4.72071886e+00, 4.04243875e+00, 4.81023622e+00, 1.53058100e+00,\n",
      "       3.55058885e+00, 3.19647908e+00, 4.59955001e+00, 5.20219994e+00,\n",
      "       4.63758087e+00, 4.04148483e+00, 1.00382781e+00, 3.72805691e+00,\n",
      "       7.54528999e-01, 2.64495826e+00, 3.00710511e+00, 2.54357600e+00,\n",
      "       3.87258816e+00, 4.49855900e+00, 4.95742083e-01, 2.24023676e+00,\n",
      "       4.45012689e+00, 4.75134206e+00, 4.54336810e+00, 4.63961196e+00,\n",
      "       2.82234478e+00, 4.32742929e+00, 2.98324084e+00, 4.92704606e+00,\n",
      "       4.27779984e+00, 4.35859585e+00, 4.85174870e+00, 4.60318303e+00,\n",
      "       4.77827525e+00, 5.54728580e+00, 5.30289984e+00, 4.27366304e+00,\n",
      "       4.48064423e+00, 4.31457305e+00, 4.30815482e+00, 2.70267725e+00,\n",
      "       5.01742411e+00, 4.99514294e+00, 4.00025010e+00, 4.31653905e+00,\n",
      "       5.09088707e+00, 3.90408707e+00, 4.15146017e+00, 4.54626918e+00,\n",
      "       4.78994799e+00, 5.08924985e+00, 5.13573384e+00, 2.51712584e+00,\n",
      "       4.90700221e+00, 4.81756115e+00, 4.67613506e+00, 1.69368124e+00,\n",
      "       4.02999806e+00, 5.59768200e+00, 2.27473927e+00, 4.15262890e+00,\n",
      "       4.45660281e+00, 4.64269614e+00, 3.22960997e+00, 4.27888513e+00,\n",
      "       4.28655815e+00, 4.34516406e+00, 4.37407327e+00, 4.63204026e+00,\n",
      "       4.90486908e+00, 4.74007106e+00, 4.96902180e+00, 4.56841898e+00,\n",
      "       4.70143795e+00, 4.80283904e+00, 4.82874894e+00, 3.94454813e+00]), array([7.83439875e-01, 1.06742501e+00, 1.01683474e+00, 8.22718859e-01,\n",
      "       8.64979982e-01, 7.86587715e-01, 9.79625225e-01, 1.02130580e+00,\n",
      "       9.84518290e-01, 6.91416025e-01, 5.38050175e-01, 8.37476730e-01,\n",
      "       8.23501110e-01, 8.00895691e-03, 1.36549950e-01, 9.18732882e-01,\n",
      "       5.86089849e-01, 1.13523936e+00, 1.17017698e+00, 8.41790915e-01,\n",
      "       9.40279007e-01, 1.00340414e+00, 7.25442886e-01, 9.32952881e-01,\n",
      "       8.87202024e-01, 9.84809160e-01, 9.27966118e-01, 5.95370054e-01,\n",
      "       8.59916925e-01, 8.47207308e-01, 7.49552011e-01, 9.28158045e-01,\n",
      "       9.28019047e-01, 6.91842079e-01, 9.75227833e-01, 8.50492954e-01,\n",
      "       9.03370857e-01, 9.70358133e-01, 1.22642398e+00, 9.29649830e-01,\n",
      "       1.12956214e+00, 1.25692534e+00, 1.70122147e-01, 8.66986990e-01,\n",
      "       9.21601057e-01, 8.39547873e-01, 9.28849936e-01, 1.02166414e+00,\n",
      "       7.69188166e-01, 8.59142065e-01, 9.67454910e-01, 9.15161133e-01,\n",
      "       8.42087984e-01, 8.21440935e-01, 8.19082975e-01, 1.19190693e+00,\n",
      "       1.02040124e+00, 7.21548080e-01, 9.20728922e-01, 9.07507181e-01,\n",
      "       7.36972809e-01, 9.92080927e-01, 8.90444040e-01, 8.57462645e-01,\n",
      "       9.01561022e-01, 9.50129986e-01, 4.02740955e-01, 8.06921005e-01,\n",
      "       9.51036930e-01, 1.04727602e+00, 1.01943111e+00, 9.26705837e-01,\n",
      "       1.01518106e+00, 7.55813122e-01, 1.05443978e+00, 1.32510591e+00,\n",
      "       1.10090208e+00, 1.35856867e-01, 5.99248886e-01, 5.55429459e-02,\n",
      "       6.57828808e-01, 5.92798948e-01, 3.88396978e-01, 8.98475647e-01,\n",
      "       8.58819962e-01, 8.17373991e-01, 8.79477024e-01, 9.01766062e-01,\n",
      "       1.00661302e+00, 9.87561941e-01, 2.88244009e-01, 9.74537849e-01,\n",
      "       9.70185041e-01, 9.88925934e-01, 7.92086601e-01, 9.22473192e-01,\n",
      "       7.61799097e-01, 9.32272911e-01, 7.92977095e-01, 8.16940784e-01,\n",
      "       9.77146149e-01, 8.70520115e-01, 8.01617861e-01, 9.69346046e-01,\n",
      "       9.70111847e-01, 8.70522976e-01, 9.84433889e-01, 8.73041868e-01,\n",
      "       9.84411240e-01, 8.83022070e-01, 1.00021005e+00, 9.12724972e-01,\n",
      "       8.17233086e-01, 2.55357981e-01, 7.10692167e-01, 2.32282162e-01,\n",
      "       9.52463865e-01, 8.93844843e-01, 1.05241704e+00, 8.56127262e-01,\n",
      "       1.01643205e+00, 8.73935699e-01, 1.00521111e+00, 9.94109869e-01,\n",
      "       8.22426796e-01, 7.62869835e-01, 8.47290039e-01, 1.00487518e+00,\n",
      "       9.75760221e-01, 8.67502928e-01, 1.01566410e+00, 7.25994110e-01,\n",
      "       8.43429565e-02, 5.79757929e-01, 8.12432051e-01, 1.01508784e+00,\n",
      "       8.74860048e-01, 7.97223091e-01, 9.44406986e-01, 9.38515902e-01,\n",
      "       9.09787178e-01, 9.04209852e-01, 1.06145501e+00, 1.85758829e-01,\n",
      "       1.01683998e+00, 9.62610960e-01, 8.86528015e-01, 1.03329110e+00,\n",
      "       7.17973948e-01, 1.07779694e+00, 1.40336275e-01, 9.62747097e-01,\n",
      "       9.45791960e-01, 8.73821020e-01, 9.08359051e-01, 1.00014186e+00,\n",
      "       8.43257904e-01, 9.97751951e-01, 1.09059811e+00, 9.19021845e-01,\n",
      "       9.53412056e-01, 9.09875870e-01, 8.20202827e-01, 1.02224422e+00,\n",
      "       8.68839741e-01, 7.08001852e-01, 8.58618259e-01, 8.22467804e-01,\n",
      "       8.48237991e-01, 1.00267792e+00, 8.98137093e-01, 9.56899881e-01,\n",
      "       1.06699491e+00, 2.76273251e-01, 8.53777885e-01, 8.02623987e-01,\n",
      "       9.27809000e-01, 9.55631971e-01, 8.63127947e-01, 8.98566008e-01,\n",
      "       9.94660139e-01, 9.60936785e-01, 8.87619972e-01, 7.12071180e-01,\n",
      "       1.04954171e+00, 8.64870787e-01, 6.27955914e-01, 5.28001785e-01,\n",
      "       5.90672255e-01, 8.07644844e-01, 8.23901892e-01, 8.91986132e-01,\n",
      "       1.16748691e+00, 9.51808929e-01, 8.38280916e-01, 9.43572998e-01,\n",
      "       9.67842102e-01, 8.76436949e-01, 7.81444073e-01, 9.78784800e-01,\n",
      "       9.11427021e-01, 7.45057106e-01, 9.27612066e-01, 8.61702919e-01,\n",
      "       7.27334023e-01, 7.60138035e-01, 1.07238913e+00, 9.16181564e-01,\n",
      "       9.76858139e-01, 1.01427412e+00, 7.94393063e-01, 9.30831909e-01,\n",
      "       8.42930079e-01, 9.38946009e-01, 1.12065506e+00, 7.25681782e-01,\n",
      "       1.02010202e+00, 1.33580709e+00, 8.70865345e-01, 9.92355108e-01,\n",
      "       8.20664644e-01, 8.69800091e-01, 9.44308043e-01, 9.22523975e-01,\n",
      "       9.92801905e-01, 9.54062939e-01, 9.65284109e-01, 9.66415882e-01,\n",
      "       8.76638889e-01, 9.80496883e-01, 8.13773155e-01, 1.01553202e+00,\n",
      "       1.02983999e+00, 8.88826132e-01, 8.80948782e-01, 8.24856758e-01,\n",
      "       7.47197866e-01, 8.08653116e-01, 8.66502762e-01, 8.55603933e-01,\n",
      "       7.61528015e-01, 5.96901178e-01, 6.98490858e-01, 7.99275160e-01,\n",
      "       6.69127941e-01, 9.53583241e-01, 9.37022209e-01, 9.66854811e-01,\n",
      "       5.05437851e-02, 7.43499994e-01, 8.99388790e-01, 1.38630915e+00,\n",
      "       9.68905926e-01, 8.57758999e-01, 7.69149065e-01, 8.15701962e-01,\n",
      "       1.00863791e+00, 5.26709557e-02, 2.31266022e-05, 8.16433907e-01,\n",
      "       8.17522049e-01, 1.01196027e+00, 1.02216005e+00, 3.89505863e-01,\n",
      "       1.02717209e+00, 9.52055931e-01, 6.48657799e-01, 3.87146950e-01,\n",
      "       7.33950138e-02, 8.38306189e-01, 4.36168909e-01, 9.82126713e-01,\n",
      "       4.04444933e-01, 6.72989845e-01, 1.91471577e-02, 3.37013960e-01,\n",
      "       1.26183987e-01, 3.59950066e-02, 7.45972157e-01, 2.70891190e-03,\n",
      "       8.53260756e-01, 9.48292017e-01, 9.08551931e-01, 3.45528126e-02,\n",
      "       7.64639854e-01, 1.16768312e+00, 7.05455065e-01, 8.33550215e-01,\n",
      "       4.10584927e-01, 9.57282066e-01, 7.99226761e-01, 6.94506884e-01,\n",
      "       8.33080053e-01, 2.93435097e-01, 2.71137714e-01, 8.42659473e-02,\n",
      "       3.86762857e-01, 8.71562004e-01, 7.47321844e-01, 7.43900061e-01,\n",
      "       5.14798641e-01, 6.12673759e-02, 9.25297022e-01, 1.03572011e+00,\n",
      "       9.07014847e-01, 8.43487978e-01, 2.94692755e-01, 7.03294039e-01,\n",
      "       9.20948982e-01, 7.91565180e-01, 8.06115627e-01, 7.26058960e-01,\n",
      "       9.11736727e-01, 5.14302254e-02, 1.04508495e+00, 9.87930775e-01,\n",
      "       1.59116983e-01, 9.90413189e-01, 1.05232692e+00, 5.95211029e-01,\n",
      "       1.27071857e-01, 8.24383020e-01, 1.18487835e-01, 1.02329230e+00,\n",
      "       1.01002979e+00, 8.54964972e-01, 7.33823061e-01, 5.41499138e-01,\n",
      "       4.88935947e-01, 1.07932782e+00, 8.29734087e-01, 8.37578058e-01,\n",
      "       8.86222124e-01, 9.10502911e-01, 7.34822989e-01, 9.09737110e-01,\n",
      "       4.16354179e-01, 1.08518124e+00, 1.05744624e+00, 9.09835815e-01,\n",
      "       1.02967501e+00, 7.01909065e-01, 8.00052166e-01, 8.70436907e-01,\n",
      "       1.12963891e+00, 9.34653282e-01, 7.95351028e-01, 1.22958827e+00,\n",
      "       1.06250119e+00, 1.84627771e-01, 1.02100396e+00, 1.39907312e+00,\n",
      "       8.57804060e-01, 9.45375919e-01, 9.17788029e-01, 9.00672913e-01,\n",
      "       9.55978394e-01, 1.12107205e+00, 8.75029087e-01, 9.72040892e-01,\n",
      "       9.06582117e-01, 1.16150594e+00, 9.21274900e-01, 9.87857819e-01,\n",
      "       1.01765609e+00, 7.75500059e-01, 8.42679024e-01, 8.86481762e-01,\n",
      "       1.23616910e+00, 8.08965921e-01, 8.52229834e-01, 8.35112810e-01,\n",
      "       1.01404786e+00, 2.94225931e-01, 9.53510046e-01, 1.16625595e+00,\n",
      "       8.92054081e-01, 8.13111067e-01, 7.26696968e-01, 8.71643066e-01,\n",
      "       9.89252090e-01, 1.67114973e-01, 8.32897186e-01, 6.34571075e-01,\n",
      "       9.30564165e-01, 5.23086071e-01, 5.81430197e-01, 5.56938887e-01,\n",
      "       3.80579948e-01, 1.12222385e+00, 1.18573904e+00, 4.54088926e-01,\n",
      "       5.80015898e-01, 6.42800331e-02, 1.91656113e-01, 3.61362934e-01,\n",
      "       8.96548986e-01, 1.35182142e-01, 2.22445011e-01, 8.62025023e-01,\n",
      "       2.27188826e-01, 9.30129051e-01, 7.84827709e-01, 9.73902225e-01,\n",
      "       7.80499935e-01, 8.76343966e-01, 1.19369102e+00, 1.05138993e+00,\n",
      "       8.32530975e-01, 9.06553745e-01, 8.12771082e-01, 8.77435923e-01,\n",
      "       9.12850857e-01, 8.78537893e-01, 9.47503805e-01, 8.98570061e-01,\n",
      "       6.79368973e-01, 1.12519908e+00, 9.09121990e-01, 9.79169846e-01,\n",
      "       1.81299925e-01, 7.92454720e-01, 1.01617479e+00, 1.01757622e+00,\n",
      "       9.73941088e-01, 7.35151052e-01, 9.19209957e-01, 2.83067942e-01,\n",
      "       6.80030107e-01, 6.57649994e-01, 9.66355085e-01, 1.03106904e+00,\n",
      "       9.24930811e-01, 6.90046310e-01, 2.15231895e-01, 7.08035231e-01,\n",
      "       1.21090174e-01, 4.97605085e-01, 5.92524052e-01, 4.53593016e-01,\n",
      "       7.76374817e-01, 9.09889936e-01, 9.85288620e-02, 5.70102930e-01,\n",
      "       1.12616992e+00, 9.77677107e-01, 8.34645987e-01, 9.47335958e-01,\n",
      "       4.94113684e-01, 7.54803896e-01, 5.49366951e-01, 9.34672832e-01,\n",
      "       7.75261879e-01, 8.32567930e-01, 8.93913031e-01, 8.93419027e-01,\n",
      "       1.00800896e+00, 1.01944804e+00, 1.00441790e+00, 8.32821846e-01,\n",
      "       7.48950005e-01, 7.61178970e-01, 9.15158749e-01, 5.09850025e-01,\n",
      "       9.96884108e-01, 8.69367599e-01, 7.37596273e-01, 8.40509892e-01,\n",
      "       9.61019754e-01, 6.82267904e-01, 7.31940746e-01, 8.72710228e-01,\n",
      "       9.24438000e-01, 9.83943939e-01, 9.85147953e-01, 4.30647850e-01,\n",
      "       8.32103968e-01, 8.44216108e-01, 7.73728132e-01, 3.43336821e-01,\n",
      "       6.69957161e-01, 1.04696822e+00, 4.26657915e-01, 7.01326132e-01,\n",
      "       8.93558025e-01, 9.46316004e-01, 5.75299025e-01, 7.75638103e-01,\n",
      "       7.23104954e-01, 9.40351963e-01, 7.75222063e-01, 9.68744993e-01,\n",
      "       9.56023216e-01, 9.24621105e-01, 9.27412033e-01, 8.17179918e-01,\n",
      "       9.15250063e-01, 9.54936028e-01, 9.17912960e-01, 7.09517956e-01]), array([1.14841700e-01, 1.57996178e-01, 1.46553993e-01, 1.16716623e-01,\n",
      "       1.27335072e-01, 1.15050077e-01, 1.50999069e-01, 1.39651060e-01,\n",
      "       1.35866165e-01, 9.77473259e-02, 7.60917664e-02, 1.27360106e-01,\n",
      "       1.27091885e-01, 1.14703178e-03, 1.70078278e-02, 1.32194042e-01,\n",
      "       8.87827873e-02, 1.71131134e-01, 1.63316011e-01, 1.26682997e-01,\n",
      "       1.32522106e-01, 1.50064945e-01, 1.13579988e-01, 1.39906168e-01,\n",
      "       1.31408930e-01, 1.41546249e-01, 1.35075092e-01, 8.57622623e-02,\n",
      "       1.23212099e-01, 1.20298862e-01, 1.14056110e-01, 1.42147779e-01,\n",
      "       1.39371157e-01, 1.01126909e-01, 1.51697874e-01, 1.28504992e-01,\n",
      "       1.26271963e-01, 1.44181013e-01, 1.78770304e-01, 1.41047001e-01,\n",
      "       1.67496920e-01, 1.78309679e-01, 2.15611458e-02, 1.23581886e-01,\n",
      "       1.45417929e-01, 1.18150949e-01, 1.35791063e-01, 1.58147097e-01,\n",
      "       1.19719982e-01, 1.23697042e-01, 1.46515369e-01, 1.37692213e-01,\n",
      "       1.26745701e-01, 1.15796089e-01, 1.29894972e-01, 1.85595036e-01,\n",
      "       1.53797150e-01, 9.75091457e-02, 1.38627768e-01, 1.40512943e-01,\n",
      "       1.08973742e-01, 1.40235901e-01, 1.27789021e-01, 1.24224901e-01,\n",
      "       1.36883020e-01, 1.41399860e-01, 5.89940548e-02, 1.22607946e-01,\n",
      "       1.43979073e-01, 1.51114941e-01, 1.44800901e-01, 1.33346796e-01,\n",
      "       1.49055004e-01, 1.11444950e-01, 1.55833244e-01, 1.88292265e-01,\n",
      "       1.62717104e-01, 1.52950287e-02, 7.66201019e-02, 6.07681274e-03,\n",
      "       9.62290764e-02, 8.38651657e-02, 5.43391705e-02, 1.44294977e-01,\n",
      "       1.30717754e-01, 1.19990826e-01, 1.31192923e-01, 1.34591103e-01,\n",
      "       1.05526209e-01, 1.49063826e-01, 3.73511314e-02, 1.45984888e-01,\n",
      "       1.46608829e-01, 1.51057005e-01, 1.17704868e-01, 1.40115023e-01,\n",
      "       1.14585161e-01, 1.36527061e-01, 1.14187002e-01, 1.26857996e-01,\n",
      "       1.53533936e-01, 1.32753134e-01, 1.22539997e-01, 1.35251999e-01,\n",
      "       1.42231941e-01, 1.29485130e-01, 1.53445005e-01, 1.41007900e-01,\n",
      "       1.40329838e-01, 1.15263939e-01, 1.55426979e-01, 1.31999969e-01,\n",
      "       1.24686241e-01, 3.37929726e-02, 1.05766058e-01, 2.85687447e-02,\n",
      "       1.44145727e-01, 1.29235983e-01, 1.51235104e-01, 1.25983000e-01,\n",
      "       1.53248072e-01, 1.25985146e-01, 1.45298958e-01, 1.41577005e-01,\n",
      "       1.24273300e-01, 1.11615896e-01, 1.28381968e-01, 1.59282207e-01,\n",
      "       1.37238979e-01, 1.22619867e-01, 1.50338173e-01, 1.16652966e-01,\n",
      "       8.34107399e-03, 8.11300278e-02, 1.28381014e-01, 1.53889179e-01,\n",
      "       1.27567053e-01, 1.22671843e-01, 1.54665947e-01, 1.44441128e-01,\n",
      "       1.32327080e-01, 1.37372971e-01, 1.55943871e-01, 2.35619545e-02,\n",
      "       1.62793159e-01, 1.46384001e-01, 1.32357836e-01, 1.64017200e-01,\n",
      "       1.03105783e-01, 1.67259693e-01, 1.52230263e-02, 1.50982141e-01,\n",
      "       1.44698143e-01, 1.28297806e-01, 1.42015934e-01, 1.46198988e-01,\n",
      "       1.29935026e-01, 1.55785084e-01, 1.62463903e-01, 1.31090879e-01,\n",
      "       1.42333031e-01, 1.35722876e-01, 1.22242689e-01, 1.58119917e-01,\n",
      "       1.26167774e-01, 1.08753920e-01, 1.26308680e-01, 1.24523878e-01,\n",
      "       1.24921083e-01, 1.40995026e-01, 1.42953157e-01, 1.50581837e-01,\n",
      "       1.79426193e-01, 3.92479897e-02, 1.20704889e-01, 1.19351149e-01,\n",
      "       1.35848999e-01, 1.48186922e-01, 1.29289150e-01, 1.35241985e-01,\n",
      "       1.40803099e-01, 1.35340214e-01, 1.33859158e-01, 1.06806040e-01,\n",
      "       1.50034904e-01, 1.23613834e-01, 8.63471031e-02, 7.32259750e-02,\n",
      "       8.42280388e-02, 1.19953156e-01, 1.28571987e-01, 1.29220247e-01,\n",
      "       1.80130959e-01, 1.58816099e-01, 1.33425951e-01, 1.41525030e-01,\n",
      "       1.50030136e-01, 1.30507946e-01, 1.19458914e-01, 1.46297216e-01,\n",
      "       1.35689974e-01, 1.07272863e-01, 1.38092041e-01, 1.22177124e-01,\n",
      "       1.04086161e-01, 1.15209103e-01, 1.57999992e-01, 1.33907795e-01,\n",
      "       1.56152964e-01, 1.64128065e-01, 1.19421005e-01, 1.41912222e-01,\n",
      "       1.23695850e-01, 1.38668060e-01, 1.68923140e-01, 1.15985870e-01,\n",
      "       1.67540073e-01, 1.97686195e-01, 1.22430086e-01, 1.36076689e-01,\n",
      "       1.26242161e-01, 1.38288021e-01, 1.49013996e-01, 1.43430233e-01,\n",
      "       1.44526005e-01, 1.48369789e-01, 1.53882980e-01, 1.47238255e-01,\n",
      "       1.35787964e-01, 1.55835867e-01, 1.20324135e-01, 1.47303820e-01,\n",
      "       1.50110960e-01, 1.29708052e-01, 1.40235901e-01, 1.16961956e-01,\n",
      "       1.14994049e-01, 1.18782997e-01, 1.25593185e-01, 1.27472162e-01,\n",
      "       1.09147310e-01, 9.13002491e-02, 1.06380224e-01, 1.19081020e-01,\n",
      "       1.04289055e-01, 1.41823053e-01, 1.37351036e-01, 1.41726971e-01,\n",
      "       5.75470924e-03, 1.04302168e-01, 1.31333113e-01, 1.97053909e-01,\n",
      "       1.39974833e-01, 1.23941183e-01, 1.13638163e-01, 1.20217800e-01,\n",
      "       1.41198874e-01, 5.50866127e-03, 2.09808350e-05, 1.18931055e-01,\n",
      "       1.15060806e-01, 1.38533115e-01, 1.53247833e-01, 5.26058674e-02,\n",
      "       1.67412996e-01, 1.48221970e-01, 8.43341351e-02, 5.15379906e-02,\n",
      "       6.90197945e-03, 1.29053831e-01, 5.91759682e-02, 1.39584064e-01,\n",
      "       5.21080494e-02, 1.00250244e-01, 1.43098831e-03, 4.13851738e-02,\n",
      "       1.43029690e-02, 3.19290161e-03, 1.05751038e-01, 6.46829605e-04,\n",
      "       1.19161129e-01, 1.41173840e-01, 1.38540983e-01, 3.38101387e-03,\n",
      "       1.09483957e-01, 1.67850971e-01, 1.02983952e-01, 1.24449253e-01,\n",
      "       5.82768917e-02, 1.51283979e-01, 1.16428852e-01, 1.01133108e-01,\n",
      "       1.21793985e-01, 3.44350338e-02, 3.11729908e-02, 7.58290291e-03,\n",
      "       5.40921688e-02, 1.33912086e-01, 1.04324102e-01, 1.10133171e-01,\n",
      "       7.05270767e-02, 6.20889664e-03, 1.33244038e-01, 1.48283958e-01,\n",
      "       1.32825851e-01, 1.23162985e-01, 4.02271748e-02, 1.03318930e-01,\n",
      "       1.33955717e-01, 1.17505074e-01, 1.13965988e-01, 1.10496044e-01,\n",
      "       1.34129047e-01, 4.88924980e-03, 1.54165983e-01, 1.54464960e-01,\n",
      "       1.86450481e-02, 1.47673845e-01, 1.53727055e-01, 8.36498737e-02,\n",
      "       1.28901005e-02, 1.18589163e-01, 1.34682655e-02, 1.54058218e-01,\n",
      "       1.48682117e-01, 1.23366117e-01, 1.10211134e-01, 8.18901062e-02,\n",
      "       6.83510303e-02, 1.55647039e-01, 1.22109175e-01, 1.20275021e-01,\n",
      "       1.22602940e-01, 1.36965990e-01, 1.09683752e-01, 1.37316942e-01,\n",
      "       5.77039719e-02, 1.61201954e-01, 1.46283865e-01, 1.39791012e-01,\n",
      "       1.50938034e-01, 9.90288258e-02, 1.17850065e-01, 1.29351854e-01,\n",
      "       1.62998915e-01, 1.36474133e-01, 1.19665861e-01, 1.69489861e-01,\n",
      "       1.49707079e-01, 2.22599506e-02, 1.45614862e-01, 1.89307213e-01,\n",
      "       1.30837917e-01, 1.42812014e-01, 1.38549089e-01, 1.30981922e-01,\n",
      "       1.41195059e-01, 1.67857170e-01, 1.34192944e-01, 1.34417057e-01,\n",
      "       1.33478880e-01, 1.63572311e-01, 1.32099867e-01, 1.52541876e-01,\n",
      "       1.46692753e-01, 1.17124081e-01, 1.21716976e-01, 1.26240969e-01,\n",
      "       1.71797037e-01, 1.25005007e-01, 1.25193119e-01, 1.15478039e-01,\n",
      "       1.44289017e-01, 3.53159904e-02, 1.41233921e-01, 1.61488056e-01,\n",
      "       1.28672123e-01, 1.26245975e-01, 1.08612061e-01, 1.28687859e-01,\n",
      "       1.39775038e-01, 1.63872242e-02, 1.26388073e-01, 8.75327587e-02,\n",
      "       1.40249014e-01, 7.62438774e-02, 7.44252205e-02, 7.75232315e-02,\n",
      "       4.84642982e-02, 1.66453123e-01, 1.86856031e-01, 5.97581863e-02,\n",
      "       8.15989971e-02, 6.58202171e-03, 2.34158039e-02, 4.43670750e-02,\n",
      "       1.30251884e-01, 1.45349503e-02, 2.95207500e-02, 1.21935844e-01,\n",
      "       2.82187462e-02, 1.44371986e-01, 1.12032890e-01, 1.40928030e-01,\n",
      "       1.19658947e-01, 1.21749878e-01, 1.68393850e-01, 1.61552191e-01,\n",
      "       1.26443148e-01, 1.36003017e-01, 1.16976976e-01, 1.25409842e-01,\n",
      "       1.41942024e-01, 1.44166946e-01, 1.43069983e-01, 1.24422073e-01,\n",
      "       1.05136871e-01, 1.67311192e-01, 1.41349077e-01, 1.49969101e-01,\n",
      "       2.02448368e-02, 1.15268946e-01, 1.46113873e-01, 1.69543028e-01,\n",
      "       1.49151087e-01, 1.12535000e-01, 1.36187077e-01, 3.73461246e-02,\n",
      "       9.89620686e-02, 8.01241398e-02, 1.46556139e-01, 1.45735264e-01,\n",
      "       1.43826962e-01, 9.97459888e-02, 2.59869099e-02, 1.07825041e-01,\n",
      "       1.33361816e-02, 6.97979927e-02, 7.86919594e-02, 6.48810863e-02,\n",
      "       1.14816904e-01, 1.40500069e-01, 1.13840103e-02, 7.97801018e-02,\n",
      "       1.30703926e-01, 1.44770861e-01, 1.25449896e-01, 1.35805845e-01,\n",
      "       7.09278584e-02, 1.07161999e-01, 7.79688358e-02, 1.32637978e-01,\n",
      "       1.04296923e-01, 1.15693092e-01, 1.34815931e-01, 1.34931087e-01,\n",
      "       1.45962000e-01, 1.44532919e-01, 1.43604994e-01, 1.29343987e-01,\n",
      "       1.10712767e-01, 1.18516922e-01, 1.45311832e-01, 6.76169395e-02,\n",
      "       1.52772665e-01, 1.30928040e-01, 1.11366987e-01, 1.25715017e-01,\n",
      "       1.51150942e-01, 1.13194227e-01, 1.08730078e-01, 1.36040926e-01,\n",
      "       1.32910967e-01, 1.45640850e-01, 1.48953199e-01, 5.59887886e-02,\n",
      "       1.23486996e-01, 1.26096964e-01, 1.20185852e-01, 4.27839756e-02,\n",
      "       1.04985952e-01, 1.47886038e-01, 5.95860481e-02, 1.02941751e-01,\n",
      "       1.31270885e-01, 1.41427040e-01, 7.75511265e-02, 1.14588976e-01,\n",
      "       1.06742144e-01, 1.30506992e-01, 1.15128040e-01, 1.40343904e-01,\n",
      "       1.44183159e-01, 1.38362885e-01, 1.43682957e-01, 1.20723009e-01,\n",
      "       1.40019894e-01, 1.42150879e-01, 1.41852140e-01, 1.06938124e-01])] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write here the code required to answer the questions stated above. You can   #\n",
    "# Add more cells at this point if you need it.                                 #\n",
    "################################################################################\n",
    "\n",
    "vocab_size = [200, 2000, 20000, 200000]\n",
    "m_ap_bow = []\n",
    "train_time_bow = []\n",
    "query_times_bow = []\n",
    "for size in vocab_size: \n",
    "    filename = 'clust/clust_flickr60_k{}.fvecs'.format(size)\n",
    "    bow = BoW(filename)\n",
    "    training_time_bow = bow.build_index(train_names, train_desc)\n",
    "    total_res, m_ap, query_time = compute_mAP(query_names, query_desc, bow, gt_file = 'holidays/holidays_images.dat')\n",
    "    m_ap_bow.append(m_ap)\n",
    "    train_time_bow.append(training_time_bow)\n",
    "    query_times_bow.append(query_time)\n",
    "    print('Vocabulary size of {}: \\n'.format(size))\n",
    "    print('MAP: {} \\n'.format(m_ap))\n",
    "    print('Training time: {} secs.'.format(training_time_bow))\n",
    "    print('Query time: {} +- {} secs.'.format(np.mean(query_time), np.std(query_time)))\n",
    "    print('\\n\\n')\n",
    "          \n",
    "\n",
    "print('Printing variables: \\n')\n",
    "print('m_ap_bow: {} \\n'.format(m_ap_bow))\n",
    "print('train_time_bow: {} \\n'.format(train_time_bow))\n",
    "print('query_times_bow: {} \\n'.format(query_times_bow))\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### TF - IDF\n",
    " As a final task of this assignment, let's implement the TF-IDF scoring scheme. Modify the `BoW` class you wrote before to include TF-IDF weighting procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoW_TfIdf(object):\n",
    "    '''\n",
    "    Class to implement the BoW model + Inverted File + TF-IDF Scoring scheme.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, vocab_file):\n",
    "        '''\n",
    "        Class constructor. You should load the vocabulary and initialize other stuff \n",
    "        required to save the inverted file and the IDF terms.\n",
    "        '''\n",
    "        self.vocab = iu.load_visual_vocab(vocab_file)\n",
    "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Complete this function to save the stuff you need for the inverted file  #\n",
    "        ############################################################################\n",
    "             \n",
    "        init_dict = [(str(i), []) for i in range(self.nwords)] \n",
    "        self.inverted = dict(init_dict)\n",
    "\n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n",
    "\n",
    "    def build_index(self, img_names, img_descs):\n",
    "        '''\n",
    "        Build an index from a set of images. Essentially, for each image, you should\n",
    "            search its descriptors in the index and fill the inverted file structure\n",
    "            in consequence. Additionally, IDF for each word should be computed here.\n",
    "\n",
    "        - img_names: An ordered list with the names of query images.\n",
    "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
    "            to the descriptors found at image i.\n",
    "        '''\n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Write this function according to the description given above.            #\n",
    "        ############################################################################\n",
    "        start = time.time()\n",
    "        for name, descs in zip(img_names, img_descs): \n",
    "            matches = self.vocab.match(descs)\n",
    "            idxs = [match.trainIdx for match in matches]\n",
    "            idxs_u = np.unique(np.array(idxs)) #para evitar imagenes repetidas en el inverted file\n",
    "            for idx in list(idxs_u):\n",
    "                self.inverted[str(idx)].append(name)\n",
    "        \n",
    "        num_imgs = len(img_names)\n",
    "        for entry in list(self.inverted.keys()):\n",
    "            den = len(self.inverted[entry])\n",
    "            idf = np.log(num_imgs/(den + 1)) # +1 to avoid zero division\n",
    "            self.inverted[entry].append(idf) #el final de cada entrada es el IDF de esa VW\n",
    "            \n",
    "        stop = time.time()\n",
    "        training_time = stop - start\n",
    "        return training_time\n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n",
    "\n",
    "    def search_image(self, descs):\n",
    "        '''\n",
    "        Search an image in the index. Use the TF-IDF here when scoring the images.\n",
    "    \n",
    "        - descs: A numpy array. It is the set descriptors extracted \n",
    "            from the query image.\n",
    "\n",
    "        RETURNS: \n",
    "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "        '''    \n",
    "        ############################################################################\n",
    "        # TODO:                                                                    #\n",
    "        # Write this function according to the description given above.            #\n",
    "        ############################################################################\n",
    "        \n",
    "        start = time.time()\n",
    "        matches = self.vocab.match(descs)\n",
    "        idxs = [match.trainIdx for match in matches]      \n",
    "        init_tf_dict = [(str(idx), 0) for idx in np.unique(np.array(idxs))]\n",
    "        tf_dic = dict(init_tf_dict)\n",
    "        \n",
    "        n_kj = descs.shape[0]\n",
    "        for entry in list(tf_dic.keys()):\n",
    "            n_ij = idxs.count(int(entry))\n",
    "            tf_dic[entry] = n_ij/n_kj # TF\n",
    "        \n",
    "        counter = {}\n",
    "        for idx in idxs: \n",
    "            tf = tf_dic[str(idx)]\n",
    "            idf_ = np.array(self.inverted[str(idx)][-1:], dtype = float)\n",
    "            retrieved_imgs = self.inverted[str(idx)][:-1] #evito el IDF\n",
    "            for ret_img in retrieved_imgs: \n",
    "                if ret_img not in list(counter.keys()): \n",
    "                    counter.setdefault(ret_img,tf*idf_) #creo la entrada con valor tf*idf\n",
    "                else: \n",
    "                    counter[ret_img] += tf*idf_ # TF-IDF \n",
    "                    \n",
    "\n",
    "        values = np.array(list(counter.values()))\n",
    "        imgs_names = list(counter.keys())\n",
    "        index_sort = np.argsort(values.flatten())[::-1] #descending order \n",
    "        best_imgs = [imgs_names[int(i)] for i in index_sort]\n",
    "        set_imgs = set(best_imgs)\n",
    "    \n",
    "        stop = time.time()\n",
    "        query_time = stop - start\n",
    "        assert len(set_imgs) == len(best_imgs), \"Duplicated Images\"\n",
    "        return best_imgs, query_time\n",
    "        #return counter\n",
    "         \n",
    "        ############################################################################\n",
    "        #                                 END OF YOUR CODE                         #\n",
    "        ############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Using the vocabularies of 200, 2K, 20K and 200K visual words and the new `BoW_TfIdf` class, answer the following questions:\n",
    "\n",
    " > **Error** \n",
    " \n",
    " > <font color = 'green'> Primero de todo me gustaría comentar un error que se produjo en la primera práctica entregada. En esta, el mAP del diccionario con 200 palabras era superior a 1. El único motivo por el cual podía estar sucediendo eso era que se devolviesen imágenes repetidas. De esta forma, el numerador de la métrica mAP podría ser superior a su denominador, el cual marca el número total de imágenes relevantes para una determianda petición. Dicho error era causado por la sentencia ``index_sort = np.argsort(values.flatten())[::-1]`` de la función ``search_image``. En un principio, el array ``values`` no se aplanaba a una sola dimensión. Al no hacer eso, dicho array constituía un vector fila con dimensiones (N,1). La función de ``np.argsort`` toma como valor por defecto el -1 en su argumento ``axis``. Esto significa que se devolvían los índices que ordenaban cada columna por separado. Al ser un vector fila, se devolvía un vecto columna de 0s, ya que el valor que ordena cada columna en un vector fila es el mismo valor de la columna. Este hecho generaba que se escogiese posteriormente siempre la misma imagen a devolver por el sistema. De esta forma para ciertas imágenes de petición se contaban más resultados relevantes (numerador del mAP) de los que realmente había (denominador). </font> \n",
    " \n",
    " > **Questions**:\n",
    " >\n",
    " > - What is the mAP obtained for each visual vocabulary?\n",
    " \n",
    " > <font color = 'blue'>Finalmente, este último caso no es más que una adaptación del BoW implementado anteriormente. En este modelo, el voto de cada palabra visual se pondera empleando el índice TF-IDF. Dicho índice mide, por un lado, la frecuencia con la que aparece una palabra en la imagen y, por otro lado, la presencia de dicha palabra en las imágenes de la base de datos. De esta forma, una palabra con gran presencia en una imagen y que aparece en pocas imágenes en la base de datos, tendrá un índice TF-IDF grande, indicando que es una palabra muy específica de la imagen de petición.</font> \n",
    " \n",
    " > - Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?\n",
    " \n",
    " > <font color = 'blue'>Se observan los mismo fenómenos que con el BoW original. A mayor tamaño de vocabulario, mejor es el mAP, más cortos son los tiempos de búsqueda y mayores son los tiempos de entrenamiento. En cuanto a si siempre es mejor utilizar vocabularios grandes, me reitero que dependerá de la aplicación a llevar a cabo,  de los recursos de memoria de los cuales se disponga y al problema del sobreajuste ya mencionado. </font>\n",
    " \n",
    " > - Analyze the effect of the **vocabulary_size** in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer.\n",
    " \n",
    " > <font color = 'blue'> El mAP y los tiempos de entrenamiento y búsqueda entre vocabularios aparecen ya comentados en el apartado anterior. En cuanto a la variabilidad de los tiempos de búsqueda, esta se sitúa en torno a un 30% respecto del tiempo medio (veáse la desviación estándar impresa por cada vocabulario). Esta variabilidad es muy semejante a la que ya presentaban los modelos de BoW originales. </font> \n",
    " \n",
    " > - Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?\n",
    " \n",
    " > <font color = 'blue'>Misma respuesta que en el anterior caso con el BoW original.</font> \n",
    " \n",
    " > - How does TF-IDF affect the performance? Better or worse? Does this make sense?\n",
    " \n",
    " > <font color = 'blue'> En un principio, y bajo un punto de vista teórico,  TF-IDF debería permitir un rendimiento mayor en la búsqueda de imágenes. Como ya se ha comentado, esto se lograría otorgando un peso mayor a aquellas imágenes con particularidades semejantes a la imagen de petición, y dando menos importancia al voto de aquellas imágenes cuyo emparejamiento con al imagen de petición se debe a rasgos muy generales y/o poco discriminativos.</font> \n",
    " \n",
    " > <font color = 'blue'>En esta práctica se puede contemplar que el mAP de los tres primeros vocabularios (200, 2K y 20K) es ligeramente mayor al obtenido usando el modelo BoW original. Curiosamente esto no es así con el vocabulario más extenso, el de 200K palabras, el cual presente un mAP ligeramente menor (una diferencia de aproximandamente 0,025). Es cierto que a cuantas más palabras, menor puede ser el TF (debido a que la frecuencia de la palabra en la imagen puede ser menor mientras que el número de palabras en esta se mantiene constante) pero mayor el IDF (mayor dispersión en el índice puede generar denominadores pequeños, mientras que el número de imágenes totales se mantiene constante en el numerador). Por lo tanto, no se me ocurre una razón evidente por la pueda suceder esto. Lo más seguro se deba a un problema de implementación.</font> \n",
    " \n",
    " > <font color = 'blue'>En cuanto a tiempos de entrenamiento y búsqueda, lógicamente el TF-IDF tarda más. Esto es así ya que durante el entrenamiento se calcula el IDF de cada palabra y durante la búsqueda se determina el TF, procesos que en el BoW original no están presentes. Para los vocabularios on menos palabras estos procesos no tardan mucho, por lo que las diferencias en dichos tiempos no son muy elevadas. Sin embargo, para el diccionario de 200K palabras sí que se nota este hecho. Los tiempos de entrenamiento en este último se disparan a casi 6 veces los del BoW original, y los tiempos de búsqueda se duplican.</font> \n",
    " \n",
    " > <font color = 'blue'>Teniendo en cuenta estos aspectos, y osbervando los resultados obtenidos en esta práctica, no se pueden concluir que el TF-IDF ofrezca mejoras considerables en los modelos BoW. Por un lado, las mejoras en los mAP no son muy llamativas e incluso puede no haber mejora, como el caso del diccionario de 200K palabras. Por otro lado, los tiempos de entrenamiento y búsqueda aumentan. Este efecto tiene aun más repercusión cuantas más palabras tenga el diccionario.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Primero una prueba con el modelo de 200 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'clust/clust_flickr60_k{}.fvecs'.format(200)\n",
    "bow_tfidf = BoW_TfIdf(filename)\n",
    "training_time_bow_t = bow_tfidf.build_index(train_names, train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res, m_ap_t, query_time_t = compute_mAP(query_names, query_desc, bow_tfidf, gt_file = 'holidays/holidays_images.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of 200: \n",
      "\n",
      "MAP: 0.08537960523563595 \n",
      "\n",
      "Training time: 12.27954888343811 secs.\n",
      "\n",
      "Query time: 14.222891308784485 +- 4.111967012733803 secs.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size of {}: \\n'.format(200))\n",
    "print('MAP: {} \\n'.format(m_ap_t))\n",
    "print('Training time: {} secs.\\n'.format(training_time_bow_t))\n",
    "print('Query time: {} +- {} secs.'.format(np.mean(query_time_t), np.std(query_time_t)))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El resto de vocabularios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of 2000: \n",
      "\n",
      "MAP: 0.43212370655112464 \n",
      "\n",
      "Training time: 11.264049053192139 secs.\n",
      "\n",
      "Query time: 5.41852991771698 +- 1.6649846774186738 secs.\n",
      "\n",
      "\n",
      "\n",
      "Vocabulary size of 20000: \n",
      "\n",
      "MAP: 0.4740974379248038 \n",
      "\n",
      "Training time: 18.268032789230347 secs.\n",
      "\n",
      "Query time: 1.2320635604858399 +- 0.4482588214361656 secs.\n",
      "\n",
      "\n",
      "\n",
      "Vocabulary size of 200000: \n",
      "\n",
      "MAP: 0.4976056966502058 \n",
      "\n",
      "Training time: 122.20123171806335 secs.\n",
      "\n",
      "Query time: 0.2757780303955078 +- 0.09117671754715873 secs.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write here the code required to answer the questions stated above. You can   #\n",
    "# Add more cells at this point if you need it.                                 #\n",
    "################################################################################\n",
    "\n",
    "m_ap_bow_tfidf = []\n",
    "train_time_bow_tfidf = []\n",
    "query_times_bow_tfidf = []\n",
    "vocab_size_ = [2000, 20000, 200000]\n",
    "for size in vocab_size_: \n",
    "    print('Vocabulary size of {}: \\n'.format(size))\n",
    "    filename = 'clust/clust_flickr60_k{}.fvecs'.format(size)\n",
    "    bow_tfidf = BoW_TfIdf(filename)\n",
    "    training_time_bow_t = bow_tfidf.build_index(train_names, train_desc)\n",
    "    total_res, m_ap_t, query_time_t = compute_mAP(query_names, query_desc, bow_tfidf, gt_file = 'holidays/holidays_images.dat')\n",
    "    res = compute_mAP(query_names, query_desc, bow_tfidf, gt_file = 'holidays/holidays_images.dat')\n",
    "    m_ap_bow_tfidf.append(m_ap_t)\n",
    "    train_time_bow_tfidf.append(training_time_bow_t)\n",
    "    query_times_bow_tfidf.append(query_time_t)\n",
    "    print('MAP: {} \\n'.format(m_ap_t))\n",
    "    print('Training time: {} secs.\\n'.format(training_time_bow_t))\n",
    "    print('Query time: {} +- {} secs.'.format(np.mean(query_time_t), np.std(query_time_t)))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py37 (IRIC UIB)",
   "language": "python",
   "name": "iric-uib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
